{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "Nguồn :\n",
    "\n",
    "https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autograd, dynamic computation graph, model classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth mentioning that, if we use all points in the training set (N) to compute the loss, we are performing a batch gradient descent. If we were to use a single point at each time, it would be a stochastic gradient descent. Anything else (n) in-between 1 and N characterizes a mini-batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In PyTorch, every method that ends with an underscore (_) makes changes in-place, meaning, they will modify the underlying variable.\n",
    "\n",
    "Trong pytorch, những hàm nào mà kết thúc với dấu _ nó sẽ thay đổi theo biến   \n",
    "\n",
    "\n",
    "#### Datatype\n",
    "Khi khởi tạo dữ liệu cần nói cho nó biết đây là biến cần đạo hàm ngược bằng thuộc tính `requires_grad=True`\n",
    "\n",
    "#### Autograd\n",
    "\n",
    "Ta sử dụng cộng trừ nhân chia bình thường để gây dựng biểu thức loss\n",
    "Sau đó sử dụng loss.backward để nói cho pytorch biết đây là điểm dừng để nó autograd (tự động tính toán đạo hàm ngược)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Data Generation\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:80]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[80:]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)\n",
    "len(y_train)\n",
    "\n",
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49671415] [-0.1382643]\n",
      "[0.80119529] [0.04511107]\n",
      "[1.02745273] [0.1880898]\n",
      "[1.19494837] [0.30062446]\n",
      "[1.31831128] [0.39019766]\n",
      "[1.40853768] [0.46243529]\n",
      "[1.47389293] [0.52156753]\n",
      "[1.52058962] [0.57077536]\n",
      "[1.55329724] [0.61245104]\n",
      "[1.57552532] [0.64839396]\n",
      "[1.58991148] [0.67995779]\n",
      "[1.59843788] [0.70816115]\n",
      "[1.60259402] [0.7337708]\n",
      "[1.60349903] [0.75736412]\n",
      "[1.60199366] [0.77937615]\n",
      "[1.59870941] [0.8001349]\n",
      "[1.59412047] [0.81988791]\n",
      "[1.58858283] [0.83882224]\n",
      "[1.58236358] [0.85707942]\n",
      "[1.57566302] [0.8747668]\n",
      "[1.56863126] [0.89196598]\n",
      "[1.56138068] [0.90873921]\n",
      "[1.55399527] [0.92513416]\n",
      "[1.54653776] [0.94118756]\n",
      "[1.53905484] [0.95692788]\n",
      "[1.53158117] [0.97237736]\n",
      "[1.52414239] [0.98755358]\n",
      "[1.51675733] [1.00247055]\n",
      "[1.50943976] [1.01713964]\n",
      "[1.50219959] [1.03157019]\n",
      "[1.49504388] [1.04577]\n",
      "[1.48797756] [1.05974573]\n",
      "[1.4810039] [1.07350312]\n",
      "[1.47412502] [1.08704728]\n",
      "[1.4673421] [1.10038276]\n",
      "[1.46065567] [1.11351372]\n",
      "[1.45406576] [1.12644402]\n",
      "[1.44757202] [1.13917725]\n",
      "[1.44117385] [1.15171682]\n",
      "[1.43487042] [1.16406598]\n",
      "[1.42866079] [1.17622785]\n",
      "[1.42254388] [1.18820543]\n",
      "[1.41651858] [1.20000166]\n",
      "[1.41058368] [1.21161937]\n",
      "[1.40473799] [1.22306133]\n",
      "[1.39898027] [1.23433026]\n",
      "[1.39330927] [1.24542882]\n",
      "[1.38772374] [1.25635962]\n",
      "[1.38222245] [1.2671252]\n",
      "[1.37680416] [1.2777281]\n",
      "[1.37146764] [1.28817077]\n",
      "[1.36621168] [1.29845566]\n",
      "[1.36103507] [1.30858514]\n",
      "[1.35593663] [1.31856158]\n",
      "[1.35091519] [1.3283873]\n",
      "[1.34596959] [1.33806456]\n",
      "[1.34109868] [1.34759562]\n",
      "[1.33630135] [1.3569827]\n",
      "[1.33157648] [1.36622795]\n",
      "[1.32692299] [1.37533354]\n",
      "[1.32233979] [1.38430156]\n",
      "[1.31782583] [1.3931341]\n",
      "[1.31338006] [1.4018332]\n",
      "[1.30900145] [1.41040089]\n",
      "[1.30468898] [1.41883914]\n",
      "[1.30044166] [1.42714992]\n",
      "[1.29625851] [1.43533514]\n",
      "[1.29213855] [1.44339671]\n",
      "[1.28808083] [1.45133649]\n",
      "[1.28408441] [1.45915633]\n",
      "[1.28014836] [1.46685803]\n",
      "[1.27627177] [1.47444338]\n",
      "[1.27245375] [1.48191414]\n",
      "[1.26869341] [1.48927203]\n",
      "[1.26498988] [1.49651877]\n",
      "[1.26134229] [1.50365604]\n",
      "[1.25774981] [1.51068548]\n",
      "[1.2542116] [1.51760872]\n",
      "[1.25072684] [1.52442738]\n",
      "[1.24729473] [1.53114303]\n",
      "[1.24391447] [1.53775722]\n",
      "[1.24058527] [1.54427149]\n",
      "[1.23730637] [1.55068735]\n",
      "[1.234077] [1.55700629]\n",
      "[1.23089642] [1.56322976]\n",
      "[1.22776388] [1.56935922]\n",
      "[1.22467867] [1.57539608]\n",
      "[1.22164007] [1.58134174]\n",
      "[1.21864737] [1.58719757]\n",
      "[1.21569989] [1.59296495]\n",
      "[1.21279693] [1.59864519]\n",
      "[1.20993782] [1.60423963]\n",
      "[1.20712191] [1.60974955]\n",
      "[1.20434854] [1.61517623]\n",
      "[1.20161707] [1.62052092]\n",
      "[1.19892686] [1.62578488]\n",
      "[1.19627729] [1.63096931]\n",
      "[1.19366775] [1.63607542]\n",
      "[1.19109764] [1.6411044]\n",
      "[1.18856634] [1.6460574]\n",
      "[1.18607329] [1.65093557]\n",
      "[1.18361791] [1.65574005]\n",
      "[1.18119961] [1.66047195]\n",
      "[1.17881785] [1.66513236]\n",
      "[1.17647207] [1.66972237]\n",
      "[1.17416173] [1.67424304]\n",
      "[1.17188629] [1.67869541]\n",
      "[1.16964522] [1.68308052]\n",
      "[1.16743802] [1.68739939]\n",
      "[1.16526415] [1.69165301]\n",
      "[1.16312313] [1.69584237]\n",
      "[1.16101445] [1.69996844]\n",
      "[1.15893763] [1.70403218]\n",
      "[1.15689218] [1.70803452]\n",
      "[1.15487763] [1.71197641]\n",
      "[1.15289352] [1.71585874]\n",
      "[1.15093938] [1.71968242]\n",
      "[1.14901476] [1.72344834]\n",
      "[1.14711922] [1.72715736]\n",
      "[1.14525231] [1.73081036]\n",
      "[1.14341361] [1.73440817]\n",
      "[1.14160268] [1.73795162]\n",
      "[1.13981912] [1.74144154]\n",
      "[1.13806249] [1.74487875]\n",
      "[1.13633241] [1.74826402]\n",
      "[1.13462846] [1.75159815]\n",
      "[1.13295025] [1.75488192]\n",
      "[1.13129739] [1.75811608]\n",
      "[1.12966951] [1.76130138]\n",
      "[1.12806621] [1.76443855]\n",
      "[1.12648714] [1.76752834]\n",
      "[1.12493193] [1.77057144]\n",
      "[1.1234002] [1.77356858]\n",
      "[1.12189162] [1.77652043]\n",
      "[1.12040583] [1.7794277]\n",
      "[1.11894248] [1.78229104]\n",
      "[1.11750124] [1.78511113]\n",
      "[1.11608178] [1.78788861]\n",
      "[1.11468376] [1.79062413]\n",
      "[1.11330685] [1.79331833]\n",
      "[1.11195075] [1.79597182]\n",
      "[1.11061514] [1.79858523]\n",
      "[1.1092997] [1.80115916]\n",
      "[1.10800413] [1.80369421]\n",
      "[1.10672814] [1.80619095]\n",
      "[1.10547142] [1.80864998]\n",
      "[1.10423369] [1.81107186]\n",
      "[1.10301466] [1.81345715]\n",
      "[1.10181404] [1.81580641]\n",
      "[1.10063157] [1.81812018]\n",
      "[1.09946695] [1.82039899]\n",
      "[1.09831993] [1.82264338]\n",
      "[1.09719024] [1.82485386]\n",
      "[1.09607761] [1.82703095]\n",
      "[1.09498179] [1.82917514]\n",
      "[1.09390253] [1.83128695]\n",
      "[1.09283957] [1.83336685]\n",
      "[1.09179267] [1.83541533]\n",
      "[1.09076158] [1.83743287]\n",
      "[1.08974607] [1.83941992]\n",
      "[1.08874591] [1.84137696]\n",
      "[1.08776085] [1.84330443]\n",
      "[1.08679067] [1.84520278]\n",
      "[1.08583515] [1.84707246]\n",
      "[1.08489407] [1.84891389]\n",
      "[1.0839672] [1.8507275]\n",
      "[1.08305433] [1.85251371]\n",
      "[1.08215526] [1.85427294]\n",
      "[1.08126977] [1.85600559]\n",
      "[1.08039765] [1.85771207]\n",
      "[1.07953871] [1.85939276]\n",
      "[1.07869275] [1.86104807]\n",
      "[1.07785956] [1.86267837]\n",
      "[1.07703896] [1.86428404]\n",
      "[1.07623076] [1.86586545]\n",
      "[1.07543477] [1.86742297]\n",
      "[1.07465081] [1.86895697]\n",
      "[1.07387868] [1.87046778]\n",
      "[1.07311823] [1.87195578]\n",
      "[1.07236926] [1.8734213]\n",
      "[1.0716316] [1.87486467]\n",
      "[1.07090509] [1.87628624]\n",
      "[1.07018956] [1.87768634]\n",
      "[1.06948483] [1.87906528]\n",
      "[1.06879075] [1.88042339]\n",
      "[1.06810716] [1.88176099]\n",
      "[1.06743389] [1.88307838]\n",
      "[1.06677079] [1.88437586]\n",
      "[1.06611771] [1.88565375]\n",
      "[1.0654745] [1.88691233]\n",
      "[1.06484101] [1.88815189]\n",
      "[1.06421708] [1.88937273]\n",
      "[1.06360258] [1.89057513]\n",
      "[1.06299737] [1.89175936]\n",
      "[1.06240129] [1.8929257]\n",
      "[1.06181422] [1.89407443]\n",
      "[1.06123602] [1.89520579]\n",
      "[1.06066656] [1.89632007]\n",
      "[1.0601057] [1.89741751]\n",
      "[1.05955331] [1.89849838]\n",
      "[1.05900927] [1.89956291]\n",
      "[1.05847344] [1.90061136]\n",
      "[1.05794571] [1.90164398]\n",
      "[1.05742595] [1.90266099]\n",
      "[1.05691405] [1.90366264]\n",
      "[1.05640988] [1.90464916]\n",
      "[1.05591332] [1.90562078]\n",
      "[1.05542427] [1.90657771]\n",
      "[1.0549426] [1.90752019]\n",
      "[1.05446821] [1.90844844]\n",
      "[1.05400099] [1.90936266]\n",
      "[1.05354082] [1.91026306]\n",
      "[1.05308761] [1.91114987]\n",
      "[1.05264124] [1.91202328]\n",
      "[1.05220162] [1.91288349]\n",
      "[1.05176864] [1.91373071]\n",
      "[1.0513422] [1.91456513]\n",
      "[1.0509222] [1.91538694]\n",
      "[1.05050855] [1.91619634]\n",
      "[1.05010115] [1.91699351]\n",
      "[1.0496999] [1.91777864]\n",
      "[1.04930471] [1.91855191]\n",
      "[1.04891549] [1.91931349]\n",
      "[1.04853215] [1.92006357]\n",
      "[1.04815461] [1.92080232]\n",
      "[1.04778276] [1.92152991]\n",
      "[1.04741654] [1.92224651]\n",
      "[1.04705585] [1.92295228]\n",
      "[1.0467006] [1.92364739]\n",
      "[1.04635073] [1.92433199]\n",
      "[1.04600613] [1.92500626]\n",
      "[1.04566675] [1.92567034]\n",
      "[1.04533249] [1.92632438]\n",
      "[1.04500328] [1.92696855]\n",
      "[1.04467904] [1.92760299]\n",
      "[1.04435971] [1.92822784]\n",
      "[1.04404519] [1.92884325]\n",
      "[1.04373543] [1.92944936]\n",
      "[1.04343035] [1.93004632]\n",
      "[1.04312988] [1.93063426]\n",
      "[1.04283394] [1.93121331]\n",
      "[1.04254248] [1.93178362]\n",
      "[1.04225542] [1.93234531]\n",
      "[1.0419727] [1.93289852]\n",
      "[1.04169424] [1.93344337]\n",
      "[1.04142] [1.93397999]\n",
      "[1.0411499] [1.9345085]\n",
      "[1.04088387] [1.93502903]\n",
      "[1.04062187] [1.9355417]\n",
      "[1.04036382] [1.93604662]\n",
      "[1.04010968] [1.93654391]\n",
      "[1.03985937] [1.93703369]\n",
      "[1.03961284] [1.93751607]\n",
      "[1.03937004] [1.93799116]\n",
      "[1.03913091] [1.93845908]\n",
      "[1.03889539] [1.93891992]\n",
      "[1.03866342] [1.93937381]\n",
      "[1.03843496] [1.93982083]\n",
      "[1.03820996] [1.94026111]\n",
      "[1.03798835] [1.94069473]\n",
      "[1.03777009] [1.94112181]\n",
      "[1.03755512] [1.94154243]\n",
      "[1.03734341] [1.94195669]\n",
      "[1.03713489] [1.9423647]\n",
      "[1.03692952] [1.94276654]\n",
      "[1.03672726] [1.94316232]\n",
      "[1.03652805] [1.94355211]\n",
      "[1.03633185] [1.94393602]\n",
      "[1.03613861] [1.94431412]\n",
      "[1.0359483] [1.94468652]\n",
      "[1.03576086] [1.94505329]\n",
      "[1.03557625] [1.94541451]\n",
      "[1.03539443] [1.94577029]\n",
      "[1.03521535] [1.94612068]\n",
      "[1.03503898] [1.94646578]\n",
      "[1.03486528] [1.94680567]\n",
      "[1.0346942] [1.94714043]\n",
      "[1.0345257] [1.94747012]\n",
      "[1.03435975] [1.94779484]\n",
      "[1.03419631] [1.94811465]\n",
      "[1.03403533] [1.94842963]\n",
      "[1.03387679] [1.94873985]\n",
      "[1.03372065] [1.94904539]\n",
      "[1.03356686] [1.9493463]\n",
      "[1.03341539] [1.94964268]\n",
      "[1.03326622] [1.94993457]\n",
      "[1.03311929] [1.95022206]\n",
      "[1.03297459] [1.9505052]\n",
      "[1.03283207] [1.95078407]\n",
      "[1.03269171] [1.95105872]\n",
      "[1.03255346] [1.95132922]\n",
      "[1.03241731] [1.95159564]\n",
      "[1.03228321] [1.95185803]\n",
      "[1.03215114] [1.95211646]\n",
      "[1.03202106] [1.95237098]\n",
      "[1.03189295] [1.95262166]\n",
      "[1.03176677] [1.95286855]\n",
      "[1.0316425] [1.95311171]\n",
      "[1.03152011] [1.9533512]\n",
      "[1.03139956] [1.95358707]\n",
      "[1.03128084] [1.95381938]\n",
      "[1.03116391] [1.95404818]\n",
      "[1.03104874] [1.95427352]\n",
      "[1.03093532] [1.95449546]\n",
      "[1.03082361] [1.95471404]\n",
      "[1.03071359] [1.95492932]\n",
      "[1.03060523] [1.95514135]\n",
      "[1.0304985] [1.95535018]\n",
      "[1.03039339] [1.95555585]\n",
      "[1.03028987] [1.95575842]\n",
      "[1.03018791] [1.95595792]\n",
      "[1.03008749] [1.95615441]\n",
      "[1.02998859] [1.95634793]\n",
      "[1.02989118] [1.95653853]\n",
      "[1.02979525] [1.95672625]\n",
      "[1.02970076] [1.95691113]\n",
      "[1.0296077] [1.95709322]\n",
      "[1.02951605] [1.95727256]\n",
      "[1.02942578] [1.95744919]\n",
      "[1.02933687] [1.95762316]\n",
      "[1.02924931] [1.95779449]\n",
      "[1.02916307] [1.95796324]\n",
      "[1.02907813] [1.95812943]\n",
      "[1.02899448] [1.95829312]\n",
      "[1.02891209] [1.95845433]\n",
      "[1.02883094] [1.95861311]\n",
      "[1.02875103] [1.95876949]\n",
      "[1.02867231] [1.9589235]\n",
      "[1.02859479] [1.95907519]\n",
      "[1.02851844] [1.95922459]\n",
      "[1.02844324] [1.95937173]\n",
      "[1.02836918] [1.95951665]\n",
      "[1.02829624] [1.95965938]\n",
      "[1.02822439] [1.95979995]\n",
      "[1.02815364] [1.9599384]\n",
      "[1.02808395] [1.96007476]\n",
      "[1.02801532] [1.96020905]\n",
      "[1.02794772] [1.96034132]\n",
      "[1.02788114] [1.96047159]\n",
      "[1.02781557] [1.9605999]\n",
      "[1.02775099] [1.96072626]\n",
      "[1.02768739] [1.96085071]\n",
      "[1.02762475] [1.96097329]\n",
      "[1.02756305] [1.96109401]\n",
      "[1.02750228] [1.96121291]\n",
      "[1.02744244] [1.96133002]\n",
      "[1.02738349] [1.96144535]\n",
      "[1.02732544] [1.96155894]\n",
      "[1.02726827] [1.96167082]\n",
      "[1.02721195] [1.961781]\n",
      "[1.02715649] [1.96188952]\n",
      "[1.02710187] [1.96199641]\n",
      "[1.02704807] [1.96210167]\n",
      "[1.02699509] [1.96220535]\n",
      "[1.0269429] [1.96230746]\n",
      "[1.0268915] [1.96240803]\n",
      "[1.02684088] [1.96250708]\n",
      "[1.02679103] [1.96260463]\n",
      "[1.02674193] [1.96270071]\n",
      "[1.02669357] [1.96279533]\n",
      "[1.02664594] [1.96288853]\n",
      "[1.02659903] [1.96298032]\n",
      "[1.02655283] [1.96307072]\n",
      "[1.02650732] [1.96315976]\n",
      "[1.02646251] [1.96324745]\n",
      "[1.02641837] [1.96333382]\n",
      "[1.02637489] [1.96341888]\n",
      "[1.02633208] [1.96350266]\n",
      "[1.02628991] [1.96358517]\n",
      "[1.02624838] [1.96366644]\n",
      "[1.02620747] [1.96374647]\n",
      "[1.02616719] [1.9638253]\n",
      "[1.02612751] [1.96390294]\n",
      "[1.02608843] [1.96397941]\n",
      "[1.02604994] [1.96405472]\n",
      "[1.02601204] [1.96412889]\n",
      "[1.0259747] [1.96420194]\n",
      "[1.02593793] [1.96427389]\n",
      "[1.02590172] [1.96434475]\n",
      "[1.02586605] [1.96441454]\n",
      "[1.02583092] [1.96448327]\n",
      "[1.02579633] [1.96455097]\n",
      "[1.02576225] [1.96461765]\n",
      "[1.02572869] [1.96468331]\n",
      "[1.02569564] [1.96474799]\n",
      "[1.02566308] [1.96481169]\n",
      "[1.02563102] [1.96487443]\n",
      "[1.02559944] [1.96493621]\n",
      "[1.02556834] [1.96499707]\n",
      "[1.02553771] [1.965057]\n",
      "[1.02550754] [1.96511603]\n",
      "[1.02547783] [1.96517417]\n",
      "[1.02544857] [1.96523143]\n",
      "[1.02541975] [1.96528783]\n",
      "[1.02539136] [1.96534337]\n",
      "[1.0253634] [1.96539808]\n",
      "[1.02533587] [1.96545195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.02530875] [1.96550502]\n",
      "[1.02528204] [1.96555728]\n",
      "[1.02525574] [1.96560875]\n",
      "[1.02522983] [1.96565945]\n",
      "[1.02520431] [1.96570938]\n",
      "[1.02517918] [1.96575855]\n",
      "[1.02515443] [1.96580698]\n",
      "[1.02513005] [1.96585468]\n",
      "[1.02510604] [1.96590166]\n",
      "[1.02508239] [1.96594793]\n",
      "[1.0250591] [1.9659935]\n",
      "[1.02503617] [1.96603839]\n",
      "[1.02501357] [1.96608259]\n",
      "[1.02499132] [1.96612613]\n",
      "[1.02496941] [1.96616901]\n",
      "[1.02494783] [1.96621124]\n",
      "[1.02492657] [1.96625283]\n",
      "[1.02490564] [1.9662938]\n",
      "[1.02488502] [1.96633414]\n",
      "[1.02486471] [1.96637388]\n",
      "[1.02484471] [1.96641302]\n",
      "[1.02482501] [1.96645156]\n",
      "[1.02480561] [1.96648952]\n",
      "[1.0247865] [1.96652691]\n",
      "[1.02476768] [1.96656374]\n",
      "[1.02474914] [1.9666]\n",
      "[1.02473089] [1.96663572]\n",
      "[1.02471291] [1.96667091]\n",
      "[1.0246952] [1.96670555]\n",
      "[1.02467776] [1.96673968]\n",
      "[1.02466058] [1.96677329]\n",
      "[1.02464367] [1.96680639]\n",
      "[1.02462701] [1.96683899]\n",
      "[1.0246106] [1.9668711]\n",
      "[1.02459443] [1.96690273]\n",
      "[1.02457852] [1.96693388]\n",
      "[1.02456284] [1.96696455]\n",
      "[1.0245474] [1.96699476]\n",
      "[1.02453219] [1.96702452]\n",
      "[1.02451721] [1.96705383]\n",
      "[1.02450246] [1.96708269]\n",
      "[1.02448793] [1.96711112]\n",
      "[1.02447362] [1.96713912]\n",
      "[1.02445953] [1.96716669]\n",
      "[1.02444565] [1.96719385]\n",
      "[1.02443198] [1.9672206]\n",
      "[1.02441852] [1.96724695]\n",
      "[1.02440526] [1.96727289]\n",
      "[1.0243922] [1.96729845]\n",
      "[1.02437933] [1.96732362]\n",
      "[1.02436666] [1.96734841]\n",
      "[1.02435419] [1.96737282]\n",
      "[1.0243419] [1.96739686]\n",
      "[1.0243298] [1.96742055]\n",
      "[1.02431788] [1.96744387]\n",
      "[1.02430614] [1.96746684]\n",
      "[1.02429457] [1.96748947]\n",
      "[1.02428318] [1.96751175]\n",
      "[1.02427197] [1.9675337]\n",
      "[1.02426092] [1.96755531]\n",
      "[1.02425004] [1.9675766]\n",
      "[1.02423933] [1.96759757]\n",
      "[1.02422877] [1.96761822]\n",
      "[1.02421838] [1.96763855]\n",
      "[1.02420814] [1.96765858]\n",
      "[1.02419806] [1.96767831]\n",
      "[1.02418813] [1.96769774]\n",
      "[1.02417835] [1.96771688]\n",
      "[1.02416872] [1.96773573]\n",
      "[1.02415923] [1.96775429]\n",
      "[1.02414989] [1.96777257]\n",
      "[1.02414069] [1.96779058]\n",
      "[1.02413162] [1.96780831]\n",
      "[1.0241227] [1.96782578]\n",
      "[1.02411391] [1.96784298]\n",
      "[1.02410525] [1.96785992]\n",
      "[1.02409672] [1.96787661]\n",
      "[1.02408832] [1.96789304]\n",
      "[1.02408005] [1.96790923]\n",
      "[1.0240719] [1.96792517]\n",
      "[1.02406388] [1.96794087]\n",
      "[1.02405597] [1.96795634]\n",
      "[1.02404819] [1.96797157]\n",
      "[1.02404052] [1.96798657]\n",
      "[1.02403297] [1.96800134]\n",
      "[1.02402554] [1.96801589]\n",
      "[1.02401822] [1.96803022]\n",
      "[1.024011] [1.96804433]\n",
      "[1.0240039] [1.96805823]\n",
      "[1.0239969] [1.96807192]\n",
      "[1.02399001] [1.96808541]\n",
      "[1.02398322] [1.96809869]\n",
      "[1.02397654] [1.96811177]\n",
      "[1.02396996] [1.96812465]\n",
      "[1.02396347] [1.96813734]\n",
      "[1.02395709] [1.96814983]\n",
      "[1.0239508] [1.96816214]\n",
      "[1.0239446] [1.96817426]\n",
      "[1.0239385] [1.9681862]\n",
      "[1.02393249] [1.96819795]\n",
      "[1.02392657] [1.96820953]\n",
      "[1.02392075] [1.96822094]\n",
      "[1.023915] [1.96823217]\n",
      "[1.02390935] [1.96824323]\n",
      "[1.02390378] [1.96825413]\n",
      "[1.0238983] [1.96826486]\n",
      "[1.0238929] [1.96827543]\n",
      "[1.02388758] [1.96828584]\n",
      "[1.02388234] [1.96829609]\n",
      "[1.02387718] [1.96830619]\n",
      "[1.02387209] [1.96831613]\n",
      "[1.02386709] [1.96832593]\n",
      "[1.02386216] [1.96833558]\n",
      "[1.0238573] [1.96834508]\n",
      "[1.02385252] [1.96835443]\n",
      "[1.02384781] [1.96836365]\n",
      "[1.02384317] [1.96837273]\n",
      "[1.0238386] [1.96838167]\n",
      "[1.0238341] [1.96839047]\n",
      "[1.02382967] [1.96839914]\n",
      "[1.02382531] [1.96840768]\n",
      "[1.02382101] [1.96841609]\n",
      "[1.02381678] [1.96842438]\n",
      "[1.02381261] [1.96843254]\n",
      "[1.0238085] [1.96844057]\n",
      "[1.02380445] [1.96844849]\n",
      "[1.02380047] [1.96845628]\n",
      "[1.02379655] [1.96846396]\n",
      "[1.02379268] [1.96847152]\n",
      "[1.02378888] [1.96847897]\n",
      "[1.02378513] [1.9684863]\n",
      "[1.02378144] [1.96849353]\n",
      "[1.0237778] [1.96850064]\n",
      "[1.02377422] [1.96850765]\n",
      "[1.02377069] [1.96851455]\n",
      "[1.02376722] [1.96852135]\n",
      "[1.0237638] [1.96852804]\n",
      "[1.02376043] [1.96853463]\n",
      "[1.02375711] [1.96854113]\n",
      "[1.02375384] [1.96854752]\n",
      "[1.02375062] [1.96855382]\n",
      "[1.02374745] [1.96856002]\n",
      "[1.02374433] [1.96856613]\n",
      "[1.02374125] [1.96857215]\n",
      "[1.02373822] [1.96857808]\n",
      "[1.02373524] [1.96858392]\n",
      "[1.0237323] [1.96858967]\n",
      "[1.02372941] [1.96859533]\n",
      "[1.02372656] [1.9686009]\n",
      "[1.02372375] [1.9686064]\n",
      "[1.02372099] [1.96861181]\n",
      "[1.02371827] [1.96861713]\n",
      "[1.02371558] [1.96862238]\n",
      "[1.02371294] [1.96862755]\n",
      "[1.02371034] [1.96863264]\n",
      "[1.02370778] [1.96863765]\n",
      "[1.02370526] [1.96864259]\n",
      "[1.02370277] [1.96864745]\n",
      "[1.02370032] [1.96865224]\n",
      "[1.02369791] [1.96865696]\n",
      "[1.02369554] [1.9686616]\n",
      "[1.0236932] [1.96866618]\n",
      "[1.0236909] [1.96867069]\n",
      "[1.02368863] [1.96867512]\n",
      "[1.02368639] [1.96867949]\n",
      "[1.02368419] [1.9686838]\n",
      "[1.02368203] [1.96868804]\n",
      "[1.02367989] [1.96869222]\n",
      "[1.02367779] [1.96869633]\n",
      "[1.02367572] [1.96870038]\n",
      "[1.02367368] [1.96870437]\n",
      "[1.02367167] [1.9687083]\n",
      "[1.0236697] [1.96871217]\n",
      "[1.02366775] [1.96871598]\n",
      "[1.02366583] [1.96871973]\n",
      "[1.02366394] [1.96872343]\n",
      "[1.02366208] [1.96872707]\n",
      "[1.02366025] [1.96873066]\n",
      "[1.02365844] [1.96873419]\n",
      "[1.02365666] [1.96873767]\n",
      "[1.02365491] [1.9687411]\n",
      "[1.02365319] [1.96874447]\n",
      "[1.02365149] [1.96874779]\n",
      "[1.02364982] [1.96875107]\n",
      "[1.02364817] [1.96875429]\n",
      "[1.02364655] [1.96875747]\n",
      "[1.02364495] [1.96876059]\n",
      "[1.02364337] [1.96876367]\n",
      "[1.02364182] [1.96876671]\n",
      "[1.0236403] [1.9687697]\n",
      "[1.02363879] [1.96877264]\n",
      "[1.02363731] [1.96877554]\n",
      "[1.02363585] [1.96877839]\n",
      "[1.02363442] [1.9687812]\n",
      "[1.023633] [1.96878397]\n",
      "[1.02363161] [1.9687867]\n",
      "[1.02363024] [1.96878938]\n",
      "[1.02362888] [1.96879203]\n",
      "[1.02362755] [1.96879463]\n",
      "[1.02362624] [1.9687972]\n",
      "[1.02362495] [1.96879973]\n",
      "[1.02362368] [1.96880221]\n",
      "[1.02362243] [1.96880467]\n",
      "[1.02362119] [1.96880708]\n",
      "[1.02361998] [1.96880946]\n",
      "[1.02361878] [1.9688118]\n",
      "[1.0236176] [1.96881411]\n",
      "[1.02361644] [1.96881638]\n",
      "[1.0236153] [1.96881861]\n",
      "[1.02361417] [1.96882082]\n",
      "[1.02361306] [1.96882299]\n",
      "[1.02361197] [1.96882513]\n",
      "[1.02361089] [1.96882723]\n",
      "[1.02360983] [1.9688293]\n",
      "[1.02360879] [1.96883135]\n",
      "[1.02360776] [1.96883336]\n",
      "[1.02360675] [1.96883534]\n",
      "[1.02360575] [1.96883729]\n",
      "[1.02360477] [1.96883921]\n",
      "[1.0236038] [1.9688411]\n",
      "[1.02360285] [1.96884297]\n",
      "[1.02360191] [1.9688448]\n",
      "[1.02360099] [1.96884661]\n",
      "[1.02360008] [1.96884839]\n",
      "[1.02359918] [1.96885014]\n",
      "[1.0235983] [1.96885187]\n",
      "[1.02359743] [1.96885357]\n",
      "[1.02359657] [1.96885525]\n",
      "[1.02359573] [1.9688569]\n",
      "[1.0235949] [1.96885852]\n",
      "[1.02359408] [1.96886012]\n",
      "[1.02359328] [1.9688617]\n",
      "[1.02359248] [1.96886325]\n",
      "[1.0235917] [1.96886478]\n",
      "[1.02359093] [1.96886629]\n",
      "[1.02359017] [1.96886777]\n",
      "[1.02358943] [1.96886923]\n",
      "[1.02358869] [1.96887067]\n",
      "[1.02358797] [1.96887209]\n",
      "[1.02358726] [1.96887348]\n",
      "[1.02358655] [1.96887486]\n",
      "[1.02358586] [1.96887621]\n",
      "[1.02358518] [1.96887754]\n",
      "[1.02358451] [1.96887886]\n",
      "[1.02358385] [1.96888015]\n",
      "[1.0235832] [1.96888142]\n",
      "[1.02358256] [1.96888268]\n",
      "[1.02358192] [1.96888391]\n",
      "[1.0235813] [1.96888513]\n",
      "[1.02358069] [1.96888633]\n",
      "[1.02358009] [1.96888751]\n",
      "[1.02357949] [1.96888867]\n",
      "[1.02357891] [1.96888982]\n",
      "[1.02357833] [1.96889095]\n",
      "[1.02357776] [1.96889206]\n",
      "[1.0235772] [1.96889315]\n",
      "[1.02357665] [1.96889423]\n",
      "[1.02357611] [1.96889529]\n",
      "[1.02357558] [1.96889633]\n",
      "[1.02357505] [1.96889736]\n",
      "[1.02357453] [1.96889838]\n",
      "[1.02357402] [1.96889938]\n",
      "[1.02357352] [1.96890036]\n",
      "[1.02357302] [1.96890133]\n",
      "[1.02357254] [1.96890228]\n",
      "[1.02357206] [1.96890322]\n",
      "[1.02357158] [1.96890415]\n",
      "[1.02357112] [1.96890506]\n",
      "[1.02357066] [1.96890596]\n",
      "[1.02357021] [1.96890684]\n",
      "[1.02356976] [1.96890771]\n",
      "[1.02356932] [1.96890857]\n",
      "[1.02356889] [1.96890941]\n",
      "[1.02356847] [1.96891024]\n",
      "[1.02356805] [1.96891106]\n",
      "[1.02356764] [1.96891187]\n",
      "[1.02356723] [1.96891266]\n",
      "[1.02356683] [1.96891345]\n",
      "[1.02356644] [1.96891422]\n",
      "[1.02356605] [1.96891498]\n",
      "[1.02356567] [1.96891572]\n",
      "[1.02356529] [1.96891646]\n",
      "[1.02356492] [1.96891719]\n",
      "[1.02356455] [1.9689179]\n",
      "[1.0235642] [1.9689186]\n",
      "[1.02356384] [1.9689193]\n",
      "[1.02356349] [1.96891998]\n",
      "[1.02356315] [1.96892065]\n",
      "[1.02356281] [1.96892131]\n",
      "[1.02356248] [1.96892197]\n",
      "[1.02356215] [1.96892261]\n",
      "[1.02356183] [1.96892324]\n",
      "[1.02356151] [1.96892386]\n",
      "[1.02356119] [1.96892448]\n",
      "[1.02356089] [1.96892508]\n",
      "[1.02356058] [1.96892568]\n",
      "[1.02356028] [1.96892626]\n",
      "[1.02355999] [1.96892684]\n",
      "[1.0235597] [1.96892741]\n",
      "[1.02355941] [1.96892797]\n",
      "[1.02355913] [1.96892852]\n",
      "[1.02355885] [1.96892906]\n",
      "[1.02355858] [1.9689296]\n",
      "[1.02355831] [1.96893012]\n",
      "[1.02355804] [1.96893064]\n",
      "[1.02355778] [1.96893115]\n",
      "[1.02355752] [1.96893166]\n",
      "[1.02355727] [1.96893215]\n",
      "[1.02355702] [1.96893264]\n",
      "[1.02355678] [1.96893312]\n",
      "[1.02355653] [1.9689336]\n",
      "[1.0235563] [1.96893406]\n",
      "[1.02355606] [1.96893452]\n",
      "[1.02355583] [1.96893497]\n",
      "[1.0235556] [1.96893542]\n",
      "[1.02355538] [1.96893586]\n",
      "[1.02355516] [1.96893629]\n",
      "[1.02355494] [1.96893672]\n",
      "[1.02355472] [1.96893714]\n",
      "[1.02355451] [1.96893755]\n",
      "[1.02355431] [1.96893796]\n",
      "[1.0235541] [1.96893836]\n",
      "[1.0235539] [1.96893875]\n",
      "[1.0235537] [1.96893914]\n",
      "[1.02355351] [1.96893952]\n",
      "[1.02355331] [1.9689399]\n",
      "[1.02355312] [1.96894027]\n",
      "[1.02355294] [1.96894064]\n",
      "[1.02355275] [1.968941]\n",
      "[1.02355257] [1.96894135]\n",
      "[1.02355239] [1.9689417]\n",
      "[1.02355222] [1.96894204]\n",
      "[1.02355204] [1.96894238]\n",
      "[1.02355187] [1.96894272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0235517] [1.96894304]\n",
      "[1.02355154] [1.96894337]\n",
      "[1.02355138] [1.96894369]\n",
      "[1.02355122] [1.968944]\n",
      "[1.02355106] [1.96894431]\n",
      "[1.0235509] [1.96894461]\n",
      "[1.02355075] [1.96894491]\n",
      "[1.0235506] [1.96894521]\n",
      "[1.02355045] [1.9689455]\n",
      "[1.0235503] [1.96894579]\n",
      "[1.02355016] [1.96894607]\n",
      "[1.02355002] [1.96894635]\n",
      "[1.02354988] [1.96894662]\n",
      "[1.02354974] [1.96894689]\n",
      "[1.0235496] [1.96894716]\n",
      "[1.02354947] [1.96894742]\n",
      "[1.02354934] [1.96894768]\n",
      "[1.02354921] [1.96894793]\n",
      "[1.02354908] [1.96894818]\n",
      "[1.02354895] [1.96894843]\n",
      "[1.02354883] [1.96894867]\n",
      "[1.02354871] [1.96894891]\n",
      "[1.02354859] [1.96894914]\n",
      "[1.02354847] [1.96894937]\n",
      "[1.02354835] [1.9689496]\n",
      "[1.02354824] [1.96894983]\n",
      "[1.02354813] [1.96895005]\n",
      "[1.02354801] [1.96895027]\n",
      "[1.0235479] [1.96895048]\n",
      "[1.0235478] [1.96895069]\n",
      "[1.02354769] [1.9689509]\n",
      "[1.02354759] [1.9689511]\n",
      "[1.02354748] [1.96895131]\n",
      "[1.02354738] [1.96895151]\n",
      "[1.02354728] [1.9689517]\n",
      "[1.02354718] [1.96895189]\n",
      "[1.02354708] [1.96895208]\n",
      "[1.02354699] [1.96895227]\n",
      "[1.0235469] [1.96895246]\n",
      "[1.0235468] [1.96895264]\n",
      "[1.02354671] [1.96895282]\n",
      "[1.02354662] [1.96895299]\n",
      "[1.02354653] [1.96895317]\n",
      "[1.02354645] [1.96895334]\n",
      "[1.02354636] [1.9689535]\n",
      "[1.02354627] [1.96895367]\n",
      "[1.02354619] [1.96895383]\n",
      "[1.02354611] [1.96895399]\n",
      "[1.02354603] [1.96895415]\n",
      "[1.02354595] [1.96895431]\n",
      "[1.02354587] [1.96895446]\n",
      "[1.02354579] [1.96895461]\n",
      "[1.02354572] [1.96895476]\n",
      "[1.02354564] [1.96895491]\n",
      "[1.02354557] [1.96895505]\n",
      "[1.0235455] [1.96895519]\n",
      "[1.02354542] [1.96895534]\n",
      "[1.02354535] [1.96895547]\n",
      "[1.02354528] [1.96895561]\n",
      "[1.02354522] [1.96895574]\n",
      "[1.02354515] [1.96895587]\n",
      "[1.02354508] [1.968956]\n",
      "[1.02354502] [1.96895613]\n",
      "[1.02354495] [1.96895626]\n",
      "[1.02354489] [1.96895638]\n",
      "[1.02354483] [1.9689565]\n",
      "[1.02354476] [1.96895663]\n",
      "[1.0235447] [1.96895674]\n",
      "[1.02354464] [1.96895686]\n",
      "[1.02354459] [1.96895698]\n",
      "[1.02354453] [1.96895709]\n",
      "[1.02354447] [1.9689572]\n",
      "[1.02354441] [1.96895731]\n",
      "[1.02354436] [1.96895742]\n",
      "[1.0235443] [1.96895752]\n",
      "[1.02354425] [1.96895763]\n",
      "[1.0235442] [1.96895773]\n",
      "[1.02354415] [1.96895783]\n",
      "[1.02354409] [1.96895793]\n",
      "[1.02354404] [1.96895803]\n",
      "[1.02354399] [1.96895813]\n",
      "[1.02354395] [1.96895823]\n",
      "[1.0235439] [1.96895832]\n",
      "[1.02354385] [1.96895841]\n",
      "[1.0235438] [1.96895851]\n",
      "[1.02354376] [1.9689586]\n",
      "[1.02354371] [1.96895868]\n",
      "[1.02354367] [1.96895877]\n",
      "[1.02354362] [1.96895886]\n",
      "[1.02354358] [1.96895894]\n",
      "[1.02354354] [1.96895903]\n",
      "[1.0235435] [1.96895911]\n",
      "[1.02354345] [1.96895919]\n",
      "[1.02354341] [1.96895927]\n",
      "[1.02354337] [1.96895935]\n",
      "[1.02354333] [1.96895943]\n",
      "[1.02354329] [1.9689595]\n",
      "[1.02354326] [1.96895958]\n",
      "[1.02354322] [1.96895965]\n",
      "[1.02354318] [1.96895972]\n",
      "[1.02354314] [1.96895979]\n",
      "[1.02354311] [1.96895987]\n",
      "[1.02354307] [1.96895994]\n",
      "[1.02354304] [1.96896]\n",
      "[1.023543] [1.96896007]\n",
      "[1.02354297] [1.96896014]\n",
      "[1.02354294] [1.9689602]\n",
      "[1.0235429] [1.96896027]\n",
      "[1.02354287] [1.96896033]\n",
      "[1.02354284] [1.96896039]\n",
      "[1.02354281] [1.96896046]\n",
      "[1.02354278] [1.96896052]\n",
      "[1.02354275] [1.96896058]\n",
      "[1.02354272] [1.96896063]\n",
      "[1.02354269] [1.96896069]\n",
      "[1.02354266] [1.96896075]\n",
      "[1.02354263] [1.96896081]\n",
      "[1.0235426] [1.96896086]\n",
      "[1.02354257] [1.96896092]\n",
      "[1.02354254] [1.96896097]\n",
      "[1.02354252] [1.96896102]\n",
      "[1.02354249] [1.96896107]\n",
      "[1.02354246] [1.96896113]\n",
      "[1.02354244] [1.96896118]\n",
      "[1.02354241] [1.96896123]\n",
      "[1.02354239] [1.96896127]\n",
      "[1.02354236] [1.96896132]\n",
      "[1.02354234] [1.96896137]\n",
      "[1.02354231] [1.96896142]\n",
      "[1.02354229] [1.96896146]\n",
      "[1.02354227] [1.96896151]\n",
      "[1.02354225] [1.96896155]\n",
      "[1.02354222] [1.9689616]\n",
      "[1.0235422] [1.96896164]\n",
      "[1.02354218] [1.96896168]\n",
      "[1.02354216] [1.96896173]\n",
      "[1.02354214] [1.96896177]\n",
      "[1.02354212] [1.96896181]\n",
      "[1.02354209] [1.96896185]\n",
      "[1.02354207] [1.96896189]\n",
      "[1.02354205] [1.96896193]\n",
      "[1.02354203] [1.96896197]\n",
      "[1.02354202] [1.968962]\n",
      "[1.023542] [1.96896204]\n",
      "[1.02354198] [1.96896208]\n",
      "[1.02354196] [1.96896211]\n",
      "[1.02354194] [1.96896215]\n",
      "[1.02354192] [1.96896218]\n",
      "[1.02354191] [1.96896222]\n",
      "[1.02354189] [1.96896225]\n",
      "[1.02354187] [1.96896229]\n",
      "[1.02354185] [1.96896232]\n",
      "[1.02354184] [1.96896235]\n",
      "[1.02354182] [1.96896238]\n",
      "[1.0235418] [1.96896242]\n",
      "[1.02354179] [1.96896245]\n",
      "[1.02354177] [1.96896248]\n",
      "[1.02354176] [1.96896251]\n",
      "[1.02354174] [1.96896254]\n",
      "[1.02354173] [1.96896257]\n",
      "[1.02354171] [1.96896259]\n",
      "[1.0235417] [1.96896262]\n",
      "[1.02354168] [1.96896265]\n",
      "[1.02354167] [1.96896268]\n",
      "[1.02354166] [1.96896271]\n",
      "[1.02354164] [1.96896273]\n",
      "[1.02354163] [1.96896276]\n",
      "[1.02354162] [1.96896278]\n",
      "[1.0235416] [1.96896281]\n",
      "[1.02354159] [1.96896283]\n",
      "[1.02354158] [1.96896286]\n",
      "[1.02354157] [1.96896288]\n",
      "[1.02354155] [1.96896291]\n",
      "[1.02354154] [1.96896293]\n",
      "[1.02354153] [1.96896295]\n",
      "[1.02354152] [1.96896298]\n",
      "[1.02354151] [1.968963]\n",
      "[1.02354149] [1.96896302]\n",
      "[1.02354148] [1.96896304]\n",
      "[1.02354147] [1.96896307]\n",
      "[1.02354146] [1.96896309]\n",
      "[1.02354145] [1.96896311]\n",
      "[1.02354144] [1.96896313]\n",
      "[1.02354143] [1.96896315]\n",
      "[1.02354142] [1.96896317]\n",
      "[1.02354141] [1.96896319]\n",
      "[1.0235414] [1.96896321]\n",
      "[1.02354139] [1.96896323]\n",
      "[1.02354138] [1.96896325]\n",
      "[1.02354137] [1.96896326]\n",
      "[1.02354136] [1.96896328]\n",
      "[1.02354135] [1.9689633]\n",
      "[1.02354134] [1.96896332]\n",
      "[1.02354133] [1.96896334]\n",
      "[1.02354133] [1.96896335]\n",
      "[1.02354132] [1.96896337]\n",
      "[1.02354131] [1.96896339]\n",
      "[1.0235413] [1.9689634]\n",
      "[1.02354129] [1.96896342]\n",
      "[1.02354128] [1.96896343]\n",
      "[1.02354128] [1.96896345]\n",
      "[1.02354127] [1.96896347]\n",
      "[1.02354126] [1.96896348]\n",
      "[1.02354125] [1.9689635]\n",
      "[1.02354125] [1.96896351]\n",
      "[1.02354124] [1.96896352]\n",
      "[1.02354123] [1.96896354]\n",
      "[1.02354122] [1.96896355]\n",
      "[1.02354122] [1.96896357]\n",
      "[1.02354121] [1.96896358]\n",
      "[1.0235412] [1.96896359]\n",
      "[1.0235412] [1.96896361]\n",
      "[1.02354119] [1.96896362]\n",
      "[1.02354118] [1.96896363]\n",
      "[1.02354118] [1.96896365]\n",
      "[1.02354117] [1.96896366]\n",
      "[1.02354116] [1.96896367]\n",
      "[1.02354116] [1.96896368]\n",
      "[1.02354115] [1.96896369]\n",
      "[1.02354115] [1.96896371]\n",
      "[1.02354114] [1.96896372]\n",
      "[1.02354113] [1.96896373]\n",
      "[1.02354113] [1.96896374]\n",
      "[1.02354112] [1.96896375]\n",
      "[1.02354112] [1.96896376]\n",
      "[1.02354111] [1.96896377]\n",
      "[1.02354111] [1.96896378]\n",
      "[1.0235411] [1.96896379]\n",
      "[1.0235411] [1.9689638]\n",
      "[1.02354109] [1.96896381]\n",
      "[1.02354108] [1.96896382]\n",
      "[1.02354108] [1.96896383]\n",
      "[1.02354108] [1.96896384]\n",
      "[1.02354107] [1.96896385]\n",
      "[1.02354107] [1.96896386]\n",
      "[1.02354106] [1.96896387]\n",
      "[1.02354106] [1.96896388]\n",
      "[1.02354105] [1.96896389]\n",
      "[1.02354105] [1.9689639]\n",
      "[1.02354104] [1.96896391]\n",
      "[1.02354104] [1.96896392]\n",
      "[1.02354103] [1.96896392]\n",
      "[1.02354103] [1.96896393]\n",
      "[1.02354103] [1.96896394]\n",
      "[1.02354102] [1.96896395]\n",
      "[1.02354102] [1.96896396]\n",
      "[1.02354101] [1.96896396]\n",
      "[1.02354101] [1.96896397]\n",
      "[1.02354101] [1.96896398]\n",
      "[1.023541] [1.96896399]\n",
      "[1.023541] [1.96896399]\n",
      "[1.02354099] [1.968964]\n",
      "[1.02354099] [1.96896401]\n",
      "[1.02354099] [1.96896402]\n",
      "[1.02354098] [1.96896402]\n",
      "[1.02354098] [1.96896403]\n",
      "[1.02354098] [1.96896404]\n",
      "[1.02354097] [1.96896404]\n",
      "[1.02354097] [1.96896405]\n",
      "[1.02354097] [1.96896405]\n",
      "[1.02354096] [1.96896406]\n",
      "[1.02354096] [1.96896407]\n",
      "[1.02354096] [1.96896407]\n",
      "[1.02354095] [1.96896408]\n",
      "[1.02354095] [1.96896409]\n",
      "[1.02354095] [1.96896409]\n",
      "[1.02354095] [1.9689641]\n",
      "[1.02354094] [1.9689641]\n",
      "[1.02354094] [1.96896411]\n",
      "[1.02354094] [1.96896411]\n",
      "[1.02354094] [1.96896411]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Initializes parameters \"a\" and \"b\" randomly\n",
    "np.random.seed(42)\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "\n",
    "print(a, b)\n",
    "\n",
    "# Sets learning rate\n",
    "lr = 1e-1\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Computes our model's predicted output\n",
    "    yhat = a + b * x_train\n",
    "    \n",
    "    # How wrong is our model? That's the error! \n",
    "    error = (y_train - yhat)\n",
    "    # It is a regression, so it computes mean squared error (MSE)\n",
    "    loss = (error ** 2).mean()\n",
    "    \n",
    "    # Computes gradients for both \"a\" and \"b\" parameters\n",
    "    a_grad = -2 * error.mean()\n",
    "    b_grad = -2 * (x_train * error).mean()\n",
    "    \n",
    "    # Updates parameters using gradients and the learning rate\n",
    "    a = a - lr * a_grad\n",
    "    b = b - lr * b_grad\n",
    "    \n",
    "    print(a, b)\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý : Đạo hàm ngược là quá trình cập nhật trọng số (đạo hàm riêng lẻ) để thay đổi sao cho khi forward thì sẽ cho ra kết quả gần giống với kết quả sau cùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.02354075] [1.96896447]\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check: do we get the same results as our gradient descent?\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linr = LinearRegression()\n",
    "linr.fit(x_train, y_train)\n",
    "print(linr.intercept_, linr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
    "# and then we send them to the chosen device\n",
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "# Here we can see the difference - notice that .type() is more useful\n",
    "# since it also tells us WHERE the tensor is (device)\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2706], requires_grad=True) tensor([-0.4380], requires_grad=True)\n",
      "tensor([0.3330], requires_grad=True) tensor([0.3203], requires_grad=True)\n",
      "tensor([-1.2678], requires_grad=True) tensor([0.1246], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# FIRST\n",
    "# Initializes parameters \"a\" and \"b\" randomly, ALMOST as we did in Numpy\n",
    "# since we want to apply gradient descent on these parameters, we need\n",
    "# to set REQUIRES_GRAD = TRUE\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(a, b)\n",
    "\n",
    "# SECOND\n",
    "# But what if we want to run it on a GPU? We could just send them to device, right?\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
    "print(a, b)\n",
    "# Sorry, but NO! The to(device) \"shadows\" the gradient...\n",
    "\n",
    "# THIRD\n",
    "# We can either create regular tensors and send them to the device (as we did with our data)\n",
    "a = torch.randn(1, dtype=torch.float).to(device)\n",
    "b = torch.randn(1, dtype=torch.float).to(device)\n",
    "# and THEN set them as requiring gradients...\n",
    "a.requires_grad_()\n",
    "b.requires_grad_()\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3367, 0.1288],\n",
      "        [0.2345, 0.2303]], requires_grad=True) tensor([[-1.1229, -0.1863],\n",
      "        [ 2.2082, -0.6380]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# We can specify the device at the moment of creation - RECOMMENDED!\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn((2,2), requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn([2,2], requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.1125])\n",
      "tensor([-1.8156])\n",
      "tensor([-2.3184])\n",
      "tensor([-1.4064])\n",
      "tensor([-1.7219])\n",
      "tensor([-1.0982])\n",
      "tensor([-1.2737])\n",
      "tensor([-0.8659])\n",
      "tensor([-0.9372])\n",
      "tensor([-0.6906])\n",
      "tensor([-0.6845])\n",
      "tensor([-0.5583])\n",
      "tensor([-0.4948])\n",
      "tensor([-0.4582])\n",
      "tensor([-0.3526])\n",
      "tensor([-0.3824])\n",
      "tensor([-0.2459])\n",
      "tensor([-0.3248])\n",
      "tensor([-0.1660])\n",
      "tensor([-0.2810])\n",
      "tensor([-0.1063])\n",
      "tensor([-0.2475])\n",
      "tensor([-0.0616])\n",
      "tensor([-0.2218])\n",
      "tensor([-0.0283])\n",
      "tensor([-0.2019])\n",
      "tensor([-0.0036])\n",
      "tensor([-0.1864])\n",
      "tensor([0.0147])\n",
      "tensor([-0.1743])\n",
      "tensor([0.0283])\n",
      "tensor([-0.1646])\n",
      "tensor([0.0382])\n",
      "tensor([-0.1568])\n",
      "tensor([0.0453])\n",
      "tensor([-0.1505])\n",
      "tensor([0.0505])\n",
      "tensor([-0.1452])\n",
      "tensor([0.0541])\n",
      "tensor([-0.1408])\n",
      "tensor([0.0566])\n",
      "tensor([-0.1370])\n",
      "tensor([0.0582])\n",
      "tensor([-0.1337])\n",
      "tensor([0.0592])\n",
      "tensor([-0.1307])\n",
      "tensor([0.0597])\n",
      "tensor([-0.1280])\n",
      "tensor([0.0599])\n",
      "tensor([-0.1255])\n",
      "tensor([0.0598])\n",
      "tensor([-0.1232])\n",
      "tensor([0.0594])\n",
      "tensor([-0.1211])\n",
      "tensor([0.0590])\n",
      "tensor([-0.1190])\n",
      "tensor([0.0584])\n",
      "tensor([-0.1170])\n",
      "tensor([0.0578])\n",
      "tensor([-0.1151])\n",
      "tensor([0.0571])\n",
      "tensor([-0.1133])\n",
      "tensor([0.0564])\n",
      "tensor([-0.1115])\n",
      "tensor([0.0557])\n",
      "tensor([-0.1098])\n",
      "tensor([0.0549])\n",
      "tensor([-0.1081])\n",
      "tensor([0.0541])\n",
      "tensor([-0.1064])\n",
      "tensor([0.0534])\n",
      "tensor([-0.1048])\n",
      "tensor([0.0526])\n",
      "tensor([-0.1032])\n",
      "tensor([0.0518])\n",
      "tensor([-0.1016])\n",
      "tensor([0.0511])\n",
      "tensor([-0.1001])\n",
      "tensor([0.0503])\n",
      "tensor([-0.0985])\n",
      "tensor([0.0496])\n",
      "tensor([-0.0970])\n",
      "tensor([0.0488])\n",
      "tensor([-0.0956])\n",
      "tensor([0.0481])\n",
      "tensor([-0.0941])\n",
      "tensor([0.0474])\n",
      "tensor([-0.0927])\n",
      "tensor([0.0466])\n",
      "tensor([-0.0913])\n",
      "tensor([0.0459])\n",
      "tensor([-0.0899])\n",
      "tensor([0.0453])\n",
      "tensor([-0.0886])\n",
      "tensor([0.0446])\n",
      "tensor([-0.0872])\n",
      "tensor([0.0439])\n",
      "tensor([-0.0859])\n",
      "tensor([0.0432])\n",
      "tensor([-0.0846])\n",
      "tensor([0.0426])\n",
      "tensor([-0.0833])\n",
      "tensor([0.0419])\n",
      "tensor([-0.0821])\n",
      "tensor([0.0413])\n",
      "tensor([-0.0808])\n",
      "tensor([0.0407])\n",
      "tensor([-0.0796])\n",
      "tensor([0.0401])\n",
      "tensor([-0.0784])\n",
      "tensor([0.0395])\n",
      "tensor([-0.0772])\n",
      "tensor([0.0389])\n",
      "tensor([-0.0761])\n",
      "tensor([0.0383])\n",
      "tensor([-0.0749])\n",
      "tensor([0.0377])\n",
      "tensor([-0.0738])\n",
      "tensor([0.0371])\n",
      "tensor([-0.0727])\n",
      "tensor([0.0366])\n",
      "tensor([-0.0716])\n",
      "tensor([0.0360])\n",
      "tensor([-0.0705])\n",
      "tensor([0.0355])\n",
      "tensor([-0.0694])\n",
      "tensor([0.0349])\n",
      "tensor([-0.0684])\n",
      "tensor([0.0344])\n",
      "tensor([-0.0673])\n",
      "tensor([0.0339])\n",
      "tensor([-0.0663])\n",
      "tensor([0.0334])\n",
      "tensor([-0.0653])\n",
      "tensor([0.0329])\n",
      "tensor([-0.0643])\n",
      "tensor([0.0324])\n",
      "tensor([-0.0634])\n",
      "tensor([0.0319])\n",
      "tensor([-0.0624])\n",
      "tensor([0.0314])\n",
      "tensor([-0.0615])\n",
      "tensor([0.0309])\n",
      "tensor([-0.0605])\n",
      "tensor([0.0305])\n",
      "tensor([-0.0596])\n",
      "tensor([0.0300])\n",
      "tensor([-0.0587])\n",
      "tensor([0.0296])\n",
      "tensor([-0.0578])\n",
      "tensor([0.0291])\n",
      "tensor([-0.0570])\n",
      "tensor([0.0287])\n",
      "tensor([-0.0561])\n",
      "tensor([0.0282])\n",
      "tensor([-0.0552])\n",
      "tensor([0.0278])\n",
      "tensor([-0.0544])\n",
      "tensor([0.0274])\n",
      "tensor([-0.0536])\n",
      "tensor([0.0270])\n",
      "tensor([-0.0528])\n",
      "tensor([0.0266])\n",
      "tensor([-0.0520])\n",
      "tensor([0.0262])\n",
      "tensor([-0.0512])\n",
      "tensor([0.0258])\n",
      "tensor([-0.0504])\n",
      "tensor([0.0254])\n",
      "tensor([-0.0497])\n",
      "tensor([0.0250])\n",
      "tensor([-0.0489])\n",
      "tensor([0.0246])\n",
      "tensor([-0.0482])\n",
      "tensor([0.0242])\n",
      "tensor([-0.0474])\n",
      "tensor([0.0239])\n",
      "tensor([-0.0467])\n",
      "tensor([0.0235])\n",
      "tensor([-0.0460])\n",
      "tensor([0.0232])\n",
      "tensor([-0.0453])\n",
      "tensor([0.0228])\n",
      "tensor([-0.0446])\n",
      "tensor([0.0225])\n",
      "tensor([-0.0440])\n",
      "tensor([0.0221])\n",
      "tensor([-0.0433])\n",
      "tensor([0.0218])\n",
      "tensor([-0.0426])\n",
      "tensor([0.0215])\n",
      "tensor([-0.0420])\n",
      "tensor([0.0211])\n",
      "tensor([-0.0414])\n",
      "tensor([0.0208])\n",
      "tensor([-0.0407])\n",
      "tensor([0.0205])\n",
      "tensor([-0.0401])\n",
      "tensor([0.0202])\n",
      "tensor([-0.0395])\n",
      "tensor([0.0199])\n",
      "tensor([-0.0389])\n",
      "tensor([0.0196])\n",
      "tensor([-0.0383])\n",
      "tensor([0.0193])\n",
      "tensor([-0.0378])\n",
      "tensor([0.0190])\n",
      "tensor([-0.0372])\n",
      "tensor([0.0187])\n",
      "tensor([-0.0366])\n",
      "tensor([0.0184])\n",
      "tensor([-0.0361])\n",
      "tensor([0.0182])\n",
      "tensor([-0.0355])\n",
      "tensor([0.0179])\n",
      "tensor([-0.0350])\n",
      "tensor([0.0176])\n",
      "tensor([-0.0345])\n",
      "tensor([0.0173])\n",
      "tensor([-0.0339])\n",
      "tensor([0.0171])\n",
      "tensor([-0.0334])\n",
      "tensor([0.0168])\n",
      "tensor([-0.0329])\n",
      "tensor([0.0166])\n",
      "tensor([-0.0324])\n",
      "tensor([0.0163])\n",
      "tensor([-0.0319])\n",
      "tensor([0.0161])\n",
      "tensor([-0.0315])\n",
      "tensor([0.0158])\n",
      "tensor([-0.0310])\n",
      "tensor([0.0156])\n",
      "tensor([-0.0305])\n",
      "tensor([0.0154])\n",
      "tensor([-0.0301])\n",
      "tensor([0.0151])\n",
      "tensor([-0.0296])\n",
      "tensor([0.0149])\n",
      "tensor([-0.0291])\n",
      "tensor([0.0147])\n",
      "tensor([-0.0287])\n",
      "tensor([0.0145])\n",
      "tensor([-0.0283])\n",
      "tensor([0.0142])\n",
      "tensor([-0.0278])\n",
      "tensor([0.0140])\n",
      "tensor([-0.0274])\n",
      "tensor([0.0138])\n",
      "tensor([-0.0270])\n",
      "tensor([0.0136])\n",
      "tensor([-0.0266])\n",
      "tensor([0.0134])\n",
      "tensor([-0.0262])\n",
      "tensor([0.0132])\n",
      "tensor([-0.0258])\n",
      "tensor([0.0130])\n",
      "tensor([-0.0254])\n",
      "tensor([0.0128])\n",
      "tensor([-0.0250])\n",
      "tensor([0.0126])\n",
      "tensor([-0.0247])\n",
      "tensor([0.0124])\n",
      "tensor([-0.0243])\n",
      "tensor([0.0122])\n",
      "tensor([-0.0239])\n",
      "tensor([0.0120])\n",
      "tensor([-0.0236])\n",
      "tensor([0.0119])\n",
      "tensor([-0.0232])\n",
      "tensor([0.0117])\n",
      "tensor([-0.0228])\n",
      "tensor([0.0115])\n",
      "tensor([-0.0225])\n",
      "tensor([0.0113])\n",
      "tensor([-0.0222])\n",
      "tensor([0.0112])\n",
      "tensor([-0.0218])\n",
      "tensor([0.0110])\n",
      "tensor([-0.0215])\n",
      "tensor([0.0108])\n",
      "tensor([-0.0212])\n",
      "tensor([0.0107])\n",
      "tensor([-0.0209])\n",
      "tensor([0.0105])\n",
      "tensor([-0.0205])\n",
      "tensor([0.0103])\n",
      "tensor([-0.0202])\n",
      "tensor([0.0102])\n",
      "tensor([-0.0199])\n",
      "tensor([0.0100])\n",
      "tensor([-0.0196])\n",
      "tensor([0.0099])\n",
      "tensor([-0.0193])\n",
      "tensor([0.0097])\n",
      "tensor([-0.0190])\n",
      "tensor([0.0096])\n",
      "tensor([-0.0187])\n",
      "tensor([0.0094])\n",
      "tensor([-0.0185])\n",
      "tensor([0.0093])\n",
      "tensor([-0.0182])\n",
      "tensor([0.0092])\n",
      "tensor([-0.0179])\n",
      "tensor([0.0090])\n",
      "tensor([-0.0176])\n",
      "tensor([0.0089])\n",
      "tensor([-0.0174])\n",
      "tensor([0.0087])\n",
      "tensor([-0.0171])\n",
      "tensor([0.0086])\n",
      "tensor([-0.0169])\n",
      "tensor([0.0085])\n",
      "tensor([-0.0166])\n",
      "tensor([0.0084])\n",
      "tensor([-0.0163])\n",
      "tensor([0.0082])\n",
      "tensor([-0.0161])\n",
      "tensor([0.0081])\n",
      "tensor([-0.0159])\n",
      "tensor([0.0080])\n",
      "tensor([-0.0156])\n",
      "tensor([0.0079])\n",
      "tensor([-0.0154])\n",
      "tensor([0.0077])\n",
      "tensor([-0.0151])\n",
      "tensor([0.0076])\n",
      "tensor([-0.0149])\n",
      "tensor([0.0075])\n",
      "tensor([-0.0147])\n",
      "tensor([0.0074])\n",
      "tensor([-0.0145])\n",
      "tensor([0.0073])\n",
      "tensor([-0.0143])\n",
      "tensor([0.0072])\n",
      "tensor([-0.0140])\n",
      "tensor([0.0071])\n",
      "tensor([-0.0138])\n",
      "tensor([0.0070])\n",
      "tensor([-0.0136])\n",
      "tensor([0.0069])\n",
      "tensor([-0.0134])\n",
      "tensor([0.0068])\n",
      "tensor([-0.0132])\n",
      "tensor([0.0066])\n",
      "tensor([-0.0130])\n",
      "tensor([0.0065])\n",
      "tensor([-0.0128])\n",
      "tensor([0.0064])\n",
      "tensor([-0.0126])\n",
      "tensor([0.0064])\n",
      "tensor([-0.0124])\n",
      "tensor([0.0063])\n",
      "tensor([-0.0122])\n",
      "tensor([0.0062])\n",
      "tensor([-0.0121])\n",
      "tensor([0.0061])\n",
      "tensor([-0.0119])\n",
      "tensor([0.0060])\n",
      "tensor([-0.0117])\n",
      "tensor([0.0059])\n",
      "tensor([-0.0115])\n",
      "tensor([0.0058])\n",
      "tensor([-0.0113])\n",
      "tensor([0.0057])\n",
      "tensor([-0.0112])\n",
      "tensor([0.0056])\n",
      "tensor([-0.0110])\n",
      "tensor([0.0055])\n",
      "tensor([-0.0108])\n",
      "tensor([0.0055])\n",
      "tensor([-0.0107])\n",
      "tensor([0.0054])\n",
      "tensor([-0.0105])\n",
      "tensor([0.0053])\n",
      "tensor([-0.0104])\n",
      "tensor([0.0052])\n",
      "tensor([-0.0102])\n",
      "tensor([0.0051])\n",
      "tensor([-0.0100])\n",
      "tensor([0.0051])\n",
      "tensor([-0.0099])\n",
      "tensor([0.0050])\n",
      "tensor([-0.0097])\n",
      "tensor([0.0049])\n",
      "tensor([-0.0096])\n",
      "tensor([0.0048])\n",
      "tensor([-0.0094])\n",
      "tensor([0.0048])\n",
      "tensor([-0.0093])\n",
      "tensor([0.0047])\n",
      "tensor([-0.0092])\n",
      "tensor([0.0046])\n",
      "tensor([-0.0090])\n",
      "tensor([0.0045])\n",
      "tensor([-0.0089])\n",
      "tensor([0.0045])\n",
      "tensor([-0.0088])\n",
      "tensor([0.0044])\n",
      "tensor([-0.0086])\n",
      "tensor([0.0043])\n",
      "tensor([-0.0085])\n",
      "tensor([0.0043])\n",
      "tensor([-0.0084])\n",
      "tensor([0.0042])\n",
      "tensor([-0.0082])\n",
      "tensor([0.0041])\n",
      "tensor([-0.0081])\n",
      "tensor([0.0041])\n",
      "tensor([-0.0080])\n",
      "tensor([0.0040])\n",
      "tensor([-0.0079])\n",
      "tensor([0.0040])\n",
      "tensor([-0.0078])\n",
      "tensor([0.0039])\n",
      "tensor([-0.0076])\n",
      "tensor([0.0038])\n",
      "tensor([-0.0075])\n",
      "tensor([0.0038])\n",
      "tensor([-0.0074])\n",
      "tensor([0.0037])\n",
      "tensor([-0.0073])\n",
      "tensor([0.0037])\n",
      "tensor([-0.0072])\n",
      "tensor([0.0036])\n",
      "tensor([-0.0071])\n",
      "tensor([0.0036])\n",
      "tensor([-0.0070])\n",
      "tensor([0.0035])\n",
      "tensor([-0.0069])\n",
      "tensor([0.0035])\n",
      "tensor([-0.0068])\n",
      "tensor([0.0034])\n",
      "tensor([-0.0067])\n",
      "tensor([0.0034])\n",
      "tensor([-0.0066])\n",
      "tensor([0.0033])\n",
      "tensor([-0.0065])\n",
      "tensor([0.0033])\n",
      "tensor([-0.0064])\n",
      "tensor([0.0032])\n",
      "tensor([-0.0063])\n",
      "tensor([0.0032])\n",
      "tensor([-0.0062])\n",
      "tensor([0.0031])\n",
      "tensor([-0.0061])\n",
      "tensor([0.0031])\n",
      "tensor([-0.0060])\n",
      "tensor([0.0030])\n",
      "tensor([-0.0059])\n",
      "tensor([0.0030])\n",
      "tensor([-0.0058])\n",
      "tensor([0.0029])\n",
      "tensor([-0.0057])\n",
      "tensor([0.0029])\n",
      "tensor([-0.0056])\n",
      "tensor([0.0028])\n",
      "tensor([-0.0055])\n",
      "tensor([0.0028])\n",
      "tensor([-0.0055])\n",
      "tensor([0.0027])\n",
      "tensor([-0.0054])\n",
      "tensor([0.0027])\n",
      "tensor([-0.0053])\n",
      "tensor([0.0027])\n",
      "tensor([-0.0052])\n",
      "tensor([0.0026])\n",
      "tensor([-0.0051])\n",
      "tensor([0.0026])\n",
      "tensor([-0.0051])\n",
      "tensor([0.0025])\n",
      "tensor([-0.0050])\n",
      "tensor([0.0025])\n",
      "tensor([-0.0049])\n",
      "tensor([0.0025])\n",
      "tensor([-0.0048])\n",
      "tensor([0.0024])\n",
      "tensor([-0.0048])\n",
      "tensor([0.0024])\n",
      "tensor([-0.0047])\n",
      "tensor([0.0024])\n",
      "tensor([-0.0046])\n",
      "tensor([0.0023])\n",
      "tensor([-0.0046])\n",
      "tensor([0.0023])\n",
      "tensor([-0.0045])\n",
      "tensor([0.0023])\n",
      "tensor([-0.0044])\n",
      "tensor([0.0022])\n",
      "tensor([-0.0043])\n",
      "tensor([0.0022])\n",
      "tensor([-0.0043])\n",
      "tensor([0.0022])\n",
      "tensor([-0.0042])\n",
      "tensor([0.0021])\n",
      "tensor([-0.0042])\n",
      "tensor([0.0021])\n",
      "tensor([-0.0041])\n",
      "tensor([0.0021])\n",
      "tensor([-0.0040])\n",
      "tensor([0.0020])\n",
      "tensor([-0.0040])\n",
      "tensor([0.0020])\n",
      "tensor([-0.0039])\n",
      "tensor([0.0020])\n",
      "tensor([-0.0038])\n",
      "tensor([0.0019])\n",
      "tensor([-0.0038])\n",
      "tensor([0.0019])\n",
      "tensor([-0.0037])\n",
      "tensor([0.0019])\n",
      "tensor([-0.0037])\n",
      "tensor([0.0019])\n",
      "tensor([-0.0036])\n",
      "tensor([0.0018])\n",
      "tensor([-0.0036])\n",
      "tensor([0.0018])\n",
      "tensor([-0.0035])\n",
      "tensor([0.0018])\n",
      "tensor([-0.0035])\n",
      "tensor([0.0017])\n",
      "tensor([-0.0034])\n",
      "tensor([0.0017])\n",
      "tensor([-0.0034])\n",
      "tensor([0.0017])\n",
      "tensor([-0.0033])\n",
      "tensor([0.0017])\n",
      "tensor([-0.0033])\n",
      "tensor([0.0016])\n",
      "tensor([-0.0032])\n",
      "tensor([0.0016])\n",
      "tensor([-0.0032])\n",
      "tensor([0.0016])\n",
      "tensor([-0.0031])\n",
      "tensor([0.0016])\n",
      "tensor([-0.0031])\n",
      "tensor([0.0015])\n",
      "tensor([-0.0030])\n",
      "tensor([0.0015])\n",
      "tensor([-0.0030])\n",
      "tensor([0.0015])\n",
      "tensor([-0.0029])\n",
      "tensor([0.0015])\n",
      "tensor([-0.0029])\n",
      "tensor([0.0015])\n",
      "tensor([-0.0028])\n",
      "tensor([0.0014])\n",
      "tensor([-0.0028])\n",
      "tensor([0.0014])\n",
      "tensor([-0.0028])\n",
      "tensor([0.0014])\n",
      "tensor([-0.0027])\n",
      "tensor([0.0014])\n",
      "tensor([-0.0027])\n",
      "tensor([0.0013])\n",
      "tensor([-0.0026])\n",
      "tensor([0.0013])\n",
      "tensor([-0.0026])\n",
      "tensor([0.0013])\n",
      "tensor([-0.0026])\n",
      "tensor([0.0013])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0025])\n",
      "tensor([0.0013])\n",
      "tensor([-0.0025])\n",
      "tensor([0.0012])\n",
      "tensor([-0.0024])\n",
      "tensor([0.0012])\n",
      "tensor([-0.0024])\n",
      "tensor([0.0012])\n",
      "tensor([-0.0024])\n",
      "tensor([0.0012])\n",
      "tensor([-0.0023])\n",
      "tensor([0.0012])\n",
      "tensor([-0.0023])\n",
      "tensor([0.0012])\n",
      "tensor([-0.0023])\n",
      "tensor([0.0011])\n",
      "tensor([-0.0022])\n",
      "tensor([0.0011])\n",
      "tensor([-0.0022])\n",
      "tensor([0.0011])\n",
      "tensor([-0.0022])\n",
      "tensor([0.0011])\n",
      "tensor([-0.0021])\n",
      "tensor([0.0011])\n",
      "tensor([-0.0021])\n",
      "tensor([0.0011])\n",
      "tensor([-0.0021])\n",
      "tensor([0.0010])\n",
      "tensor([-0.0020])\n",
      "tensor([0.0010])\n",
      "tensor([-0.0020])\n",
      "tensor([0.0010])\n",
      "tensor([-0.0020])\n",
      "tensor([0.0010])\n",
      "tensor([-0.0019])\n",
      "tensor([0.0010])\n",
      "tensor([-0.0019])\n",
      "tensor([0.0010])\n",
      "tensor([-0.0019])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0019])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0018])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0018])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0018])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0017])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0017])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0017])\n",
      "tensor([0.0009])\n",
      "tensor([-0.0017])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0016])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0016])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0016])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0016])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0015])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0015])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0015])\n",
      "tensor([0.0008])\n",
      "tensor([-0.0015])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0015])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0014])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0014])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0014])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0014])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0013])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0013])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0013])\n",
      "tensor([0.0007])\n",
      "tensor([-0.0013])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0013])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0012])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0012])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0012])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0012])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0012])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0012])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0011])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0011])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0011])\n",
      "tensor([0.0006])\n",
      "tensor([-0.0011])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0011])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0011])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0010])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0010])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0010])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0010])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0010])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0010])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0005])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0009])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0008])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0004])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0007])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0006])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0003])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0005])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0004])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0002])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0003])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([0.0001])\n",
      "tensor([-0.0002])\n",
      "tensor([9.9594e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([9.7900e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([9.6527e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([9.5085e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([9.3636e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([9.2130e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([9.0872e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.9555e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.8250e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.6918e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.5517e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.4095e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.2712e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.1570e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([8.0486e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([7.9145e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([7.8051e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([7.6955e-05])\n",
      "tensor([-0.0002])\n",
      "tensor([7.5681e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([7.4613e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([7.3319e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([7.2196e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([7.1032e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.9903e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.8819e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.7823e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.6842e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.5867e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.4933e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.4093e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.3060e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.2128e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.1231e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([6.0351e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.9320e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.8340e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.7453e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.6731e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.5748e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.4913e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.4107e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.3402e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.2584e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.1776e-05])\n",
      "tensor([-0.0001])\n",
      "tensor([5.1087e-05])\n",
      "tensor([-9.9639e-05])\n",
      "tensor([5.0304e-05])\n",
      "tensor([-9.8126e-05])\n",
      "tensor([4.9497e-05])\n",
      "tensor([-9.6684e-05])\n",
      "tensor([4.8653e-05])\n",
      "tensor([-9.5258e-05])\n",
      "tensor([4.7852e-05])\n",
      "tensor([-9.3863e-05])\n",
      "tensor([4.7217e-05])\n",
      "tensor([-9.2393e-05])\n",
      "tensor([4.6496e-05])\n",
      "tensor([-9.0986e-05])\n",
      "tensor([4.5731e-05])\n",
      "tensor([-8.9653e-05])\n",
      "tensor([4.5108e-05])\n",
      "tensor([-8.8273e-05])\n",
      "tensor([4.4387e-05])\n",
      "tensor([-8.6958e-05])\n",
      "tensor([4.3814e-05])\n",
      "tensor([-8.5594e-05])\n",
      "tensor([4.3082e-05])\n",
      "tensor([-8.4333e-05])\n",
      "tensor([4.2502e-05])\n",
      "tensor([-8.3017e-05])\n",
      "tensor([4.1800e-05])\n",
      "tensor([-8.1784e-05])\n",
      "tensor([4.1258e-05])\n",
      "tensor([-8.0489e-05])\n",
      "tensor([4.0558e-05])\n",
      "tensor([-7.9301e-05])\n",
      "tensor([3.9983e-05])\n",
      "tensor([-7.8079e-05])\n",
      "tensor([3.9203e-05])\n",
      "tensor([-7.6996e-05])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.8651e-05])\n",
      "tensor([-7.5801e-05])\n",
      "tensor([3.8224e-05])\n",
      "tensor([-7.4577e-05])\n",
      "tensor([3.7707e-05])\n",
      "tensor([-7.3411e-05])\n",
      "tensor([3.7103e-05])\n",
      "tensor([-7.2301e-05])\n",
      "tensor([3.6565e-05])\n",
      "tensor([-7.1188e-05])\n",
      "tensor([3.5924e-05])\n",
      "tensor([-7.0153e-05])\n",
      "tensor([3.5397e-05])\n",
      "tensor([-6.9097e-05])\n",
      "tensor([3.4793e-05])\n",
      "tensor([-6.8070e-05])\n",
      "tensor([3.4280e-05])\n",
      "tensor([-6.7045e-05])\n",
      "tensor([3.3689e-05])\n",
      "tensor([-6.6071e-05])\n",
      "tensor([3.3202e-05])\n",
      "tensor([-6.5076e-05])\n",
      "tensor([3.2708e-05])\n",
      "tensor([-6.4070e-05])\n",
      "tensor([3.2351e-05])\n",
      "tensor([-6.3039e-05])\n",
      "tensor([3.1894e-05])\n",
      "tensor([-6.2071e-05])\n",
      "tensor([3.1338e-05])\n",
      "tensor([-6.1164e-05])\n",
      "tensor([3.0884e-05])\n",
      "tensor([-6.0245e-05])\n",
      "tensor([3.0420e-05])\n",
      "tensor([-5.9323e-05])\n",
      "tensor([2.9829e-05])\n",
      "tensor([-5.8492e-05])\n",
      "tensor([2.9391e-05])\n",
      "tensor([-5.7597e-05])\n",
      "tensor([2.8837e-05])\n",
      "tensor([-5.6787e-05])\n",
      "tensor([2.8545e-05])\n",
      "tensor([-5.5844e-05])\n",
      "tensor([2.8068e-05])\n",
      "tensor([-5.5038e-05])\n",
      "tensor([2.7576e-05])\n",
      "tensor([-5.4227e-05])\n",
      "tensor([2.7157e-05])\n",
      "tensor([-5.3417e-05])\n",
      "tensor([2.6736e-05])\n",
      "tensor([-5.2609e-05])\n",
      "tensor([2.6422e-05])\n",
      "tensor([-5.1769e-05])\n",
      "tensor([2.6061e-05])\n",
      "tensor([-5.0980e-05])\n",
      "tensor([2.5658e-05])\n",
      "tensor([-5.0211e-05])\n",
      "tensor([2.5140e-05])\n",
      "tensor([-4.9515e-05])\n",
      "tensor([2.4863e-05])\n",
      "tensor([-4.8710e-05])\n",
      "tensor([2.4470e-05])\n",
      "tensor([-4.7986e-05])\n",
      "tensor([2.3977e-05])\n",
      "tensor([-4.7319e-05])\n",
      "tensor([2.3683e-05])\n",
      "tensor([-4.6571e-05])\n",
      "tensor([2.3326e-05])\n",
      "tensor([-4.5855e-05])\n",
      "tensor([2.2854e-05])\n",
      "tensor([-4.5239e-05])\n",
      "tensor([2.2599e-05])\n",
      "tensor([-4.4503e-05])\n",
      "tensor([2.2242e-05])\n",
      "tensor([-4.3847e-05])\n",
      "tensor([2.1889e-05])\n",
      "tensor([-4.3183e-05])\n",
      "tensor([2.1613e-05])\n",
      "tensor([-4.2511e-05])\n",
      "tensor([2.1397e-05])\n",
      "tensor([-4.1805e-05])\n",
      "tensor([2.1038e-05])\n",
      "tensor([-4.1201e-05])\n",
      "tensor([2.0693e-05])\n",
      "tensor([-4.0582e-05])\n",
      "tensor([2.0460e-05])\n",
      "tensor([-3.9930e-05])\n",
      "tensor([2.0135e-05])\n",
      "tensor([-3.9340e-05])\n",
      "tensor([1.9830e-05])\n",
      "tensor([-3.8748e-05])\n",
      "tensor([1.9469e-05])\n",
      "tensor([-3.8179e-05])\n",
      "tensor([1.9224e-05])\n",
      "tensor([-3.7587e-05])\n",
      "tensor([1.9010e-05])\n",
      "tensor([-3.6972e-05])\n",
      "tensor([1.8727e-05])\n",
      "tensor([-3.6408e-05])\n",
      "tensor([1.8393e-05])\n",
      "tensor([-3.5875e-05])\n",
      "tensor([1.8167e-05])\n",
      "tensor([-3.5313e-05])\n",
      "tensor([1.7991e-05])\n",
      "tensor([-3.4717e-05])\n",
      "tensor([1.7695e-05])\n",
      "tensor([-3.4217e-05])\n",
      "tensor([1.7414e-05])\n",
      "tensor([-3.3695e-05])\n",
      "tensor([1.6962e-05])\n",
      "tensor([-3.3284e-05])\n",
      "tensor([1.6761e-05])\n",
      "tensor([-3.2756e-05])\n",
      "tensor([1.6481e-05])\n",
      "tensor([-3.2283e-05])\n",
      "tensor([1.6171e-05])\n",
      "tensor([-3.1830e-05])\n",
      "tensor([1.5909e-05])\n",
      "tensor([-3.1345e-05])\n",
      "tensor([1.5728e-05])\n",
      "tensor([-3.0850e-05])\n",
      "tensor([1.5565e-05])\n",
      "tensor([-3.0346e-05])\n",
      "tensor([1.5289e-05])\n",
      "tensor([-2.9915e-05])\n",
      "tensor([1.4985e-05])\n",
      "tensor([-2.9496e-05])\n",
      "tensor([1.4713e-05])\n",
      "tensor([-2.9066e-05])\n",
      "tensor([1.4536e-05])\n",
      "tensor([-2.8615e-05])\n",
      "tensor([1.4409e-05])\n",
      "tensor([-2.8138e-05])\n",
      "tensor([1.4251e-05])\n",
      "tensor([-2.7683e-05])\n",
      "tensor([1.3953e-05])\n",
      "tensor([-2.7311e-05])\n",
      "tensor([1.3675e-05])\n",
      "tensor([-2.6926e-05])\n",
      "tensor([1.3649e-05])\n",
      "tensor([-2.6419e-05])\n",
      "tensor([1.3523e-05])\n",
      "tensor([-2.5994e-05])\n",
      "tensor([1.3353e-05])\n",
      "tensor([-2.5577e-05])\n",
      "tensor([1.3141e-05])\n",
      "tensor([-2.5200e-05])\n",
      "tensor([1.2852e-05])\n",
      "tensor([-2.4875e-05])\n",
      "tensor([1.2607e-05])\n",
      "tensor([-2.4519e-05])\n",
      "tensor([1.2361e-05])\n",
      "tensor([-2.4166e-05])\n",
      "tensor([1.2211e-05])\n",
      "tensor([-2.3796e-05])\n",
      "tensor([1.2074e-05])\n",
      "tensor([-2.3412e-05])\n",
      "tensor([1.1940e-05])\n",
      "tensor([-2.3025e-05])\n",
      "tensor([1.1698e-05])\n",
      "tensor([-2.2717e-05])\n",
      "tensor([1.1454e-05])\n",
      "tensor([-2.2411e-05])\n",
      "tensor([1.1186e-05])\n",
      "tensor([-2.2111e-05])\n",
      "tensor([1.1191e-05])\n",
      "tensor([-2.1685e-05])\n",
      "tensor([1.1090e-05])\n",
      "tensor([-2.1328e-05])\n",
      "tensor([1.0991e-05])\n",
      "tensor([-2.0966e-05])\n",
      "tensor([1.0841e-05])\n",
      "tensor([-2.0638e-05])\n",
      "tensor([1.0597e-05])\n",
      "tensor([-2.0378e-05])\n",
      "tensor([1.0381e-05])\n",
      "tensor([-2.0099e-05])\n",
      "tensor([1.0172e-05])\n",
      "tensor([-1.9811e-05])\n",
      "tensor([9.9134e-06])\n",
      "tensor([-1.9561e-05])\n",
      "tensor([9.8250e-06])\n",
      "tensor([-1.9239e-05])\n",
      "tensor([9.7390e-06])\n",
      "tensor([-1.8921e-05])\n",
      "tensor([9.5970e-06])\n",
      "tensor([-1.8628e-05])\n",
      "tensor([9.5194e-06])\n",
      "tensor([-1.8312e-05])\n",
      "tensor([9.2852e-06])\n",
      "tensor([-1.8094e-05])\n",
      "tensor([9.0717e-06])\n",
      "tensor([-1.7856e-05])\n",
      "tensor([8.8692e-06])\n",
      "tensor([-1.7605e-05])\n",
      "tensor([8.8958e-06])\n",
      "tensor([-1.7261e-05])\n",
      "tensor([8.7665e-06])\n",
      "tensor([-1.7017e-05])\n",
      "tensor([8.7046e-06])\n",
      "tensor([-1.6718e-05])\n",
      "tensor([8.5874e-06])\n",
      "tensor([-1.6478e-05])\n",
      "tensor([8.4943e-06])\n",
      "tensor([-1.6209e-05])\n",
      "tensor([8.4157e-06])\n",
      "tensor([-1.5924e-05])\n",
      "tensor([8.2179e-06])\n",
      "tensor([-1.5733e-05])\n",
      "tensor([8.0168e-06])\n",
      "tensor([-1.5523e-05])\n",
      "tensor([7.8037e-06])\n",
      "tensor([-1.5343e-05])\n",
      "tensor([7.5677e-06])\n",
      "tensor([-1.5163e-05])\n",
      "tensor([7.6334e-06])\n",
      "tensor([-1.4845e-05])\n",
      "tensor([7.5613e-06])\n",
      "tensor([-1.4610e-05])\n",
      "tensor([7.4733e-06])\n",
      "tensor([-1.4378e-05])\n",
      "tensor([7.3778e-06])\n",
      "tensor([-1.4175e-05])\n",
      "tensor([7.3089e-06])\n",
      "tensor([-1.3923e-05])\n",
      "tensor([7.2326e-06])\n",
      "tensor([-1.3692e-05])\n",
      "tensor([7.0194e-06])\n",
      "tensor([-1.3552e-05])\n",
      "tensor([6.8325e-06])\n",
      "tensor([-1.3394e-05])\n",
      "tensor([6.6640e-06])\n",
      "tensor([-1.3220e-05])\n",
      "tensor([6.4909e-06])\n",
      "tensor([-1.3052e-05])\n",
      "tensor([6.4964e-06])\n",
      "tensor([-1.2812e-05])\n",
      "tensor([6.5639e-06])\n",
      "tensor([-1.2530e-05])\n",
      "tensor([6.3789e-06])\n",
      "tensor([-1.2365e-05])\n",
      "tensor([6.2872e-06])\n",
      "tensor([-1.2195e-05])\n",
      "tensor([6.2519e-06])\n",
      "tensor([-1.1981e-05])\n",
      "tensor([6.1895e-06])\n",
      "tensor([-1.1794e-05])\n",
      "tensor([6.1168e-06])\n",
      "tensor([-1.1602e-05])\n",
      "tensor([6.0374e-06])\n",
      "tensor([-1.1412e-05])\n",
      "tensor([5.9709e-06])\n",
      "tensor([-1.1222e-05])\n",
      "tensor([5.8024e-06])\n",
      "tensor([-1.1109e-05])\n",
      "tensor([5.6330e-06])\n",
      "tensor([-1.0981e-05])\n",
      "tensor([5.4591e-06])\n",
      "tensor([-1.0858e-05])\n",
      "tensor([5.2679e-06])\n",
      "tensor([-1.0748e-05])\n",
      "tensor([5.3230e-06])\n",
      "tensor([-1.0534e-05])\n",
      "tensor([5.3825e-06])\n",
      "tensor([-1.0292e-05])\n",
      "tensor([5.1946e-06])\n",
      "tensor([-1.0184e-05])\n",
      "tensor([5.2743e-06])\n",
      "tensor([-9.9508e-06])\n",
      "tensor([5.2585e-06])\n",
      "tensor([-9.7615e-06])\n",
      "tensor([5.1573e-06])\n",
      "tensor([-9.6367e-06])\n",
      "tensor([5.1380e-06])\n",
      "tensor([-9.4601e-06])\n",
      "tensor([5.0936e-06])\n",
      "tensor([-9.3075e-06])\n",
      "tensor([4.9816e-06])\n",
      "tensor([-9.1954e-06])\n",
      "tensor([4.9298e-06])\n",
      "tensor([-9.0375e-06])\n",
      "tensor([4.8937e-06])\n",
      "tensor([-8.8774e-06])\n",
      "tensor([4.7355e-06])\n",
      "tensor([-8.7903e-06])\n",
      "tensor([4.5751e-06])\n",
      "tensor([-8.7056e-06])\n",
      "tensor([4.4171e-06])\n",
      "tensor([-8.6267e-06])\n",
      "tensor([4.2355e-06])\n",
      "tensor([-8.5554e-06])\n",
      "tensor([4.0668e-06])\n",
      "tensor([-8.4818e-06])\n",
      "tensor([4.1467e-06])\n",
      "tensor([-8.2836e-06])\n",
      "tensor([4.2254e-06])\n",
      "tensor([-8.0930e-06])\n",
      "tensor([4.0760e-06])\n",
      "tensor([-8.0023e-06])\n",
      "tensor([4.1328e-06])\n",
      "tensor([-7.8172e-06])\n",
      "tensor([4.2046e-06])\n",
      "tensor([-7.6315e-06])\n",
      "tensor([3.9215e-06])\n",
      "tensor([-7.6343e-06])\n",
      "tensor([3.8948e-06])\n",
      "tensor([-7.5120e-06])\n",
      "tensor([3.8606e-06])\n",
      "tensor([-7.3902e-06])\n",
      "tensor([3.7850e-06])\n",
      "tensor([-7.3009e-06])\n",
      "tensor([3.7834e-06])\n",
      "tensor([-7.1593e-06])\n",
      "tensor([3.7203e-06])\n",
      "tensor([-7.0526e-06])\n",
      "tensor([3.6638e-06])\n",
      "tensor([-6.9528e-06])\n",
      "tensor([3.6689e-06])\n",
      "tensor([-6.8133e-06])\n",
      "tensor([3.6275e-06])\n",
      "tensor([-6.6917e-06])\n",
      "tensor([3.5784e-06])\n",
      "tensor([-6.5880e-06])\n",
      "tensor([3.5308e-06])\n",
      "tensor([-6.4719e-06])\n",
      "tensor([3.3776e-06])\n",
      "tensor([-6.4364e-06])\n",
      "tensor([3.2437e-06])\n",
      "tensor([-6.3800e-06])\n",
      "tensor([3.0675e-06])\n",
      "tensor([-6.3659e-06])\n",
      "tensor([2.9166e-06])\n",
      "tensor([-6.3259e-06])\n",
      "tensor([3.0048e-06])\n",
      "tensor([-6.1637e-06])\n",
      "tensor([2.8514e-06])\n",
      "tensor([-6.1282e-06])\n",
      "tensor([2.9250e-06])\n",
      "tensor([-5.9746e-06])\n",
      "tensor([3.0333e-06])\n",
      "tensor([-5.8159e-06])\n",
      "tensor([2.9064e-06])\n",
      "tensor([-5.7573e-06])\n",
      "tensor([2.9392e-06])\n",
      "tensor([-5.6362e-06])\n",
      "tensor([3.0205e-06])\n",
      "tensor([-5.4921e-06])\n",
      "tensor([2.9093e-06])\n",
      "tensor([-5.4233e-06])\n",
      "tensor([2.9686e-06])\n",
      "tensor([-5.2866e-06])\n",
      "tensor([2.9444e-06])\n",
      "tensor([-5.2088e-06])\n",
      "tensor([2.9089e-06])\n",
      "tensor([-5.1401e-06])\n",
      "tensor([2.9280e-06])\n",
      "tensor([-5.0343e-06])\n",
      "tensor([2.8831e-06])\n",
      "tensor([-4.9754e-06])\n",
      "tensor([2.8463e-06])\n",
      "tensor([-4.8953e-06])\n",
      "tensor([2.8370e-06])\n",
      "tensor([-4.8150e-06])\n",
      "tensor([2.7919e-06])\n",
      "tensor([-4.7446e-06])\n",
      "tensor([2.7611e-06])\n",
      "tensor([-4.6727e-06])\n",
      "tensor([2.7717e-06])\n",
      "tensor([-4.5722e-06])\n",
      "tensor([2.7131e-06])\n",
      "tensor([-4.5154e-06])\n",
      "tensor([2.6944e-06])\n",
      "tensor([-4.4465e-06])\n",
      "tensor([2.6653e-06])\n",
      "tensor([-4.3539e-06])\n",
      "tensor([2.6430e-06])\n",
      "tensor([-4.2807e-06])\n",
      "tensor([2.6186e-06])\n",
      "tensor([-4.1943e-06])\n",
      "tensor([2.5853e-06])\n",
      "tensor([-4.1222e-06])\n",
      "tensor([2.4510e-06])\n",
      "tensor([-4.1212e-06])\n",
      "tensor([2.3207e-06])\n",
      "tensor([-4.1233e-06])\n",
      "tensor([2.1803e-06])\n",
      "tensor([-4.1167e-06])\n",
      "tensor([2.0407e-06])\n",
      "tensor([-4.1139e-06])\n",
      "tensor([1.9112e-06])\n",
      "tensor([-4.1103e-06])\n",
      "tensor([1.7481e-06])\n",
      "tensor([-4.1249e-06])\n",
      "tensor([1.8650e-06])\n",
      "tensor([-3.9954e-06])\n",
      "tensor([1.7448e-06])\n",
      "tensor([-3.9776e-06])\n",
      "tensor([1.7895e-06])\n",
      "tensor([-3.9126e-06])\n",
      "tensor([1.6539e-06])\n",
      "tensor([-3.9030e-06])\n",
      "tensor([1.7954e-06])\n",
      "tensor([-3.7527e-06])\n",
      "tensor([1.6313e-06])\n",
      "tensor([-3.7805e-06])\n",
      "tensor([1.7231e-06])\n",
      "tensor([-3.6585e-06])\n",
      "tensor([1.8488e-06])\n",
      "tensor([-3.5299e-06])\n",
      "tensor([1.7000e-06])\n",
      "tensor([-3.5376e-06])\n",
      "tensor([1.8062e-06])\n",
      "tensor([-3.4200e-06])\n",
      "tensor([1.6400e-06])\n",
      "tensor([-3.4362e-06])\n",
      "tensor([1.7443e-06])\n",
      "tensor([-3.3185e-06])\n",
      "tensor([1.8582e-06])\n",
      "tensor([-3.1966e-06])\n",
      "tensor([1.7043e-06])\n",
      "tensor([-3.2061e-06])\n",
      "tensor([1.8179e-06])\n",
      "tensor([-3.0808e-06])\n",
      "tensor([1.6859e-06])\n",
      "tensor([-3.0717e-06])\n",
      "tensor([1.7888e-06])\n",
      "tensor([-2.9605e-06])\n",
      "tensor([1.5330e-06])\n",
      "tensor([-3.0368e-06])\n",
      "tensor([1.6415e-06])\n",
      "tensor([-2.9110e-06])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6052e-06])\n",
      "tensor([-2.8973e-06])\n",
      "tensor([1.5740e-06])\n",
      "tensor([-2.8721e-06])\n",
      "tensor([1.6280e-06])\n",
      "tensor([-2.7748e-06])\n",
      "tensor([1.6018e-06])\n",
      "tensor([-2.7442e-06])\n",
      "tensor([1.5683e-06])\n",
      "tensor([-2.7200e-06])\n",
      "tensor([1.5324e-06])\n",
      "tensor([-2.7094e-06])\n",
      "tensor([1.5143e-06])\n",
      "tensor([-2.6750e-06])\n",
      "tensor([1.5338e-06])\n",
      "tensor([-2.6159e-06])\n",
      "tensor([1.5271e-06])\n",
      "tensor([-2.5660e-06])\n",
      "tensor([1.5131e-06])\n",
      "tensor([-2.5269e-06])\n",
      "tensor([1.4782e-06])\n",
      "tensor([-2.5077e-06])\n",
      "tensor([1.5043e-06])\n",
      "tensor([-2.4402e-06])\n",
      "tensor([1.4775e-06])\n",
      "tensor([-2.4112e-06])\n",
      "tensor([1.4729e-06])\n",
      "tensor([-2.3637e-06])\n",
      "tensor([1.4377e-06])\n",
      "tensor([-2.3390e-06])\n",
      "tensor([1.4158e-06])\n",
      "tensor([-2.3076e-06])\n",
      "tensor([1.4075e-06])\n",
      "tensor([-2.2663e-06])\n",
      "tensor([1.3832e-06])\n",
      "tensor([-2.2354e-06])\n",
      "tensor([1.3728e-06])\n",
      "tensor([-2.1949e-06])\n",
      "tensor([1.3587e-06])\n",
      "tensor([-2.1585e-06])\n",
      "tensor([1.3668e-06])\n",
      "tensor([-2.1037e-06])\n",
      "tensor([1.3468e-06])\n",
      "tensor([-2.0684e-06])\n",
      "tensor([1.3252e-06])\n",
      "tensor([-2.0346e-06])\n",
      "tensor([1.2870e-06])\n",
      "tensor([-2.0225e-06])\n",
      "tensor([1.3121e-06])\n",
      "tensor([-1.9546e-06])\n",
      "tensor([1.2775e-06])\n",
      "tensor([-1.9293e-06])\n",
      "tensor([1.2558e-06])\n",
      "tensor([-1.8950e-06])\n",
      "tensor([1.2472e-06])\n",
      "tensor([-1.8566e-06])\n",
      "tensor([1.2209e-06])\n",
      "tensor([-1.8266e-06])\n",
      "tensor([1.2135e-06])\n",
      "tensor([-1.7829e-06])\n",
      "tensor([1.1082e-06])\n",
      "tensor([-1.8117e-06])\n",
      "tensor([1.1006e-06])\n",
      "tensor([-1.7641e-06])\n",
      "tensor([9.7632e-07])\n",
      "tensor([-1.7986e-06])\n",
      "tensor([9.7539e-07])\n",
      "tensor([-1.7582e-06])\n",
      "tensor([8.0356e-07])\n",
      "tensor([-1.8217e-06])\n",
      "tensor([8.1823e-07])\n",
      "tensor([-1.7640e-06])\n",
      "tensor([6.8819e-07])\n",
      "tensor([-1.8052e-06])\n",
      "tensor([6.7143e-07])\n",
      "tensor([-1.7707e-06])\n",
      "tensor([5.7038e-07])\n",
      "tensor([-1.7968e-06])\n",
      "tensor([7.9436e-07])\n",
      "tensor([-1.6379e-06])\n",
      "tensor([6.8540e-07])\n",
      "tensor([-1.6615e-06])\n",
      "tensor([5.5338e-07])\n",
      "tensor([-1.6991e-06])\n",
      "tensor([6.2975e-07])\n",
      "tensor([-1.6509e-06])\n",
      "tensor([5.2428e-07])\n",
      "tensor([-1.6757e-06])\n",
      "tensor([6.0367e-07])\n",
      "tensor([-1.6287e-06])\n",
      "tensor([5.0268e-07])\n",
      "tensor([-1.6558e-06])\n",
      "tensor([5.9878e-07])\n",
      "tensor([-1.5878e-06])\n",
      "tensor([4.6077e-07])\n",
      "tensor([-1.6291e-06])\n",
      "tensor([6.1322e-07])\n",
      "tensor([-1.5286e-06])\n",
      "tensor([4.5472e-07])\n",
      "tensor([-1.5798e-06])\n",
      "tensor([5.9442e-07])\n",
      "tensor([-1.4876e-06])\n",
      "tensor([7.1566e-07])\n",
      "tensor([-1.4041e-06])\n",
      "tensor([5.7905e-07])\n",
      "tensor([-1.4518e-06])\n",
      "tensor([7.1316e-07])\n",
      "tensor([-1.3691e-06])\n",
      "tensor([5.7695e-07])\n",
      "tensor([-1.4135e-06])\n",
      "tensor([6.8895e-07])\n",
      "tensor([-1.3313e-06])\n",
      "tensor([5.7020e-07])\n",
      "tensor([-1.3629e-06])\n",
      "tensor([6.6496e-07])\n",
      "tensor([-1.3030e-06])\n",
      "tensor([5.4319e-07])\n",
      "tensor([-1.3332e-06])\n",
      "tensor([6.3772e-07])\n",
      "tensor([-1.2715e-06])\n",
      "tensor([5.2160e-07])\n",
      "tensor([-1.2996e-06])\n",
      "tensor([6.2003e-07])\n",
      "tensor([-1.2364e-06])\n",
      "tensor([5.0204e-07])\n",
      "tensor([-1.2649e-06])\n",
      "tensor([6.1165e-07])\n",
      "tensor([-1.1917e-06])\n",
      "tensor([4.8836e-07])\n",
      "tensor([-1.2334e-06])\n",
      "tensor([6.0169e-07])\n",
      "tensor([-1.1534e-06])\n",
      "tensor([4.7975e-07])\n",
      "tensor([-1.1903e-06])\n",
      "tensor([6.0309e-07])\n",
      "tensor([-1.1031e-06])\n",
      "tensor([4.7206e-07])\n",
      "tensor([-1.1449e-06])\n",
      "tensor([5.8918e-07])\n",
      "tensor([-1.0631e-06])\n",
      "tensor([6.9622e-07])\n",
      "tensor([-1.0042e-06])\n",
      "tensor([5.5681e-07])\n",
      "tensor([-1.0437e-06])\n",
      "tensor([6.6601e-07])\n",
      "tensor([-9.7105e-07])\n",
      "tensor([5.3446e-07])\n",
      "tensor([-1.0067e-06])\n",
      "tensor([6.4389e-07])\n",
      "tensor([-9.3217e-07])\n",
      "tensor([5.2887e-07])\n",
      "tensor([-9.6860e-07])\n",
      "tensor([6.5553e-07])\n",
      "tensor([-8.7361e-07])\n",
      "tensor([5.4983e-07])\n",
      "tensor([-9.0632e-07])\n",
      "tensor([6.3831e-07])\n",
      "tensor([-8.4148e-07])\n",
      "tensor([5.1101e-07])\n",
      "tensor([-8.8318e-07])\n",
      "tensor([6.2899e-07])\n",
      "tensor([-8.0283e-07])\n",
      "tensor([5.2544e-07])\n",
      "tensor([-8.2533e-07])\n",
      "tensor([6.2108e-07])\n",
      "tensor([-7.6744e-07])\n",
      "tensor([4.7981e-07])\n",
      "tensor([-8.0618e-07])\n",
      "tensor([5.8505e-07])\n",
      "tensor([-7.2928e-07])\n",
      "tensor([7.1654e-07])\n",
      "tensor([-6.4241e-07])\n",
      "tensor([5.8761e-07])\n",
      "tensor([-6.8365e-07])\n",
      "tensor([6.7259e-07])\n",
      "tensor([-6.2917e-07])\n",
      "tensor([5.8272e-07])\n",
      "tensor([-6.5076e-07])\n",
      "tensor([6.8586e-07])\n",
      "tensor([-5.7608e-07])\n",
      "tensor([4.5373e-07])\n",
      "tensor([-6.8860e-07])\n",
      "tensor([5.7620e-07])\n",
      "tensor([-6.0361e-07])\n",
      "tensor([6.7911e-07])\n",
      "tensor([-5.3330e-07])\n",
      "tensor([4.4022e-07])\n",
      "tensor([-6.4343e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([5.4640e-07])\n",
      "tensor([-5.7230e-07])\n",
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # No more manual computation of gradients! \n",
    "    # a_grad = -2 * error.mean()\n",
    "    # b_grad = -2 * (x_tensor * error).mean()\n",
    "    \n",
    "    # We just tell PyTorch to work its way BACKWARDS from the specified loss!\n",
    "    loss.backward()\n",
    "    # Let's check the computed gradients...\n",
    "    print(a.grad)\n",
    "    print(b.grad)\n",
    "    \n",
    "    # What about UPDATING the parameters? Not so fast...\n",
    "    \n",
    "    # FIRST ATTEMPT\n",
    "    # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
    "    # a = a - lr * a.grad\n",
    "    # b = b - lr * b.grad\n",
    "    # print(a)\n",
    "\n",
    "    # SECOND ATTEMPT\n",
    "    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
    "    # a -= lr * a.grad\n",
    "    # b -= lr * b.grad        \n",
    "    \n",
    "    # THIRD ATTEMPT\n",
    "    # We need to use NO_GRAD to keep the update out of the gradient computation\n",
    "    # Why is that? It boils down to the DYNAMIC GRAPH that PyTorch uses...\n",
    "    with torch.no_grad():\n",
    "        a -= lr * a.grad\n",
    "        b -= lr * b.grad\n",
    "    \n",
    "    # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7475, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "\n",
    "yhat = a + b * x_train_tensor\n",
    "error = y_train_tensor - yhat\n",
    "loss = (error ** 2).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    loss.backward()    \n",
    "    \n",
    "    # No more manual update!\n",
    "    # with torch.no_grad():\n",
    "    #     a -= lr * a.grad\n",
    "    #     b -= lr * b.grad\n",
    "    optimizer.step()\n",
    "    \n",
    "    # No more telling PyTorch to let gradients go!\n",
    "    # a.grad.zero_()\n",
    "    # b.grad.zero_()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
      "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    yhat = a + b * x_train_tensor\n",
    "    \n",
    "    # No more manual loss!\n",
    "    # error = y_tensor - yhat\n",
    "    # loss = (error ** 2).mean()\n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout thì chỉ sử dụng cho quá trình training, không sử dụng cho quá trình evalutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\n",
    "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.a + self.b * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a', tensor([0.3367])), ('b', tensor([0.1288]))])\n",
      "OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = ManualLinearRegression().to(device)\n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # What is this?!?\n",
    "    model.train()\n",
    "\n",
    "    # No more manual prediction!\n",
    "    # yhat = a + b * x_tensor\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "1 model.train()\n",
      "2 yhat = model(x_train_tensor)\n",
      "forward\n",
      "2.4 loss.backward()\n",
      "3 loss.backward()\n",
      "4 optimizer.step()\n",
      "5 optimizer.zero_grad()\n",
      "OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # What is this?!?\n",
    "    print(\"1 model.train()\")\n",
    "    model.train()\n",
    "\n",
    "    # No more manual prediction!\n",
    "    # yhat = a + b * x_tensor\n",
    "    print(\"2 yhat = model(x_train_tensor)\")\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    print(\"2.4 loss.backward()\")\n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "    print(\"3 loss.backward()\")\n",
    "    loss.backward()\n",
    "    print(\"4 optimizer.step()\")\n",
    "    optimizer.step()\n",
    "    print(\"5 optimizer.zero_grad()\")\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of our custom parameters, we use a Linear layer with single input and single output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Now it only takes a call to the layer to make predictions\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.7645]])), ('linear.bias', tensor([0.8300]))])\n",
      "OrderedDict([('linear.weight', tensor([[1.9690]])), ('linear.bias', tensor([1.0235]))])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = LayerLinearRegression().to(device)\n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())\n",
    "\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # What is this?!?\n",
    "    model.train()\n",
    "\n",
    "    # No more manual prediction!\n",
    "    # yhat = a + b * x_tensor\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "    loss.backward()    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2191]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2018], requires_grad=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*LayerLinearRegression().parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.train()` để báo cho pytorch biết đang ở chế độ training, không phải chế độ evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[1.9690]])), ('linear.bias', tensor([1.0235]))])\n",
      "OrderedDict([('linear.weight', tensor([[1.9690]])), ('linear.bias', tensor([1.0235]))])\n"
     ]
    }
   ],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def train_step(x, y):\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "        # Makes predictions\n",
    "        yhat = model(x)\n",
    "        # Computes loss\n",
    "        loss = loss_fn(y, yhat)\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "        # Updates parameters and zeroes gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return train_step\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # Performs one train step and returns the corresponding loss\n",
    "    loss = train_step(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)\n",
    "    \n",
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n",
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[1.9698]])), ('linear.bias', tensor([1.0255]))])\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
    "        # therefore, we need to send those mini-batches to the\n",
    "        # device where the model \"lives\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.no_grad()` : để nói cho pytorch biết chỉ có feedward chứ không đạo hàm ngược lại\n",
    "\n",
    "`eval()` : cho biết đang ở chế độ evaluation (không phải `.train()`), nên không có quá tính toán đạo hàm ngược lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[1.9559]])), ('linear.bias', tensor([1.0289]))])\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "            val_loss = loss_fn(y_val, yhat)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        y = F.relu(F.max_pool2d(self.conv1(y), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rand(): argument 'size' must be tuple of ints, but found element of type tuple at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-908b56db0705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\ProgramFile\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;31m# print(type(x[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFile\\Anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# batch_size of 2 for batchnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0min_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;31m# print(type(x[0]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: rand(): argument 'size' must be tuple of ints, but found element of type tuple at pos 2"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=((1, 28, 28), (1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def summary(model,  m,input_size, batch_size=-1, device=torch.device('cuda:0'), dtypes=None):\n",
    "    result, params_info = summary_string(\n",
    "        model, input_size, batch_size, device, dtypes)\n",
    "    print(result)\n",
    "\n",
    "    return params_info\n",
    "\n",
    "\n",
    "def summary_string(model, input_size, batch_size=-1, device=torch.device('cuda:0'), dtypes=None):\n",
    "    if dtypes == None:\n",
    "        dtypes = [torch.FloatTensor]*len(input_size)\n",
    "\n",
    "    summary_str = ''\n",
    "\n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "\n",
    "            m_key = \"%s-%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # multiple inputs to the network\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # batch_size of 2 for batchnorm\n",
    "    x = [torch.rand(2, *in_size).type(dtype).to(device=device)\n",
    "         for in_size, dtype in zip(input_size, dtypes)]\n",
    "\n",
    "    # create properties\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # make a forward pass\n",
    "    # print(x.shape)\n",
    "    model(*x)\n",
    "\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    summary_str += \"----------------------------------------------------------------\" + \"\\n\"\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "        \"Layer (type)\", \"Output Shape\", \"Param #\")\n",
    "    summary_str += line_new + \"\\n\"\n",
    "    summary_str += \"================================================================\" + \"\\n\"\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        # input_shape, output_shape, trainable, nb_params\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        summary_str += line_new + \"\\n\"\n",
    "\n",
    "    # assume 4 bytes/number (float on cuda).\n",
    "    total_input_size = abs(np.prod(sum(input_size, ()))\n",
    "                           * batch_size * 4. / (1024 ** 2.))\n",
    "    total_output_size = abs(2. * total_output * 4. /\n",
    "                            (1024 ** 2.))  # x2 for gradients\n",
    "    total_params_size = abs(total_params * 4. / (1024 ** 2.))\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "\n",
    "    summary_str += \"================================================================\" + \"\\n\"\n",
    "    summary_str += \"Total params: {0:,}\".format(total_params) + \"\\n\"\n",
    "    summary_str += \"Trainable params: {0:,}\".format(trainable_params) + \"\\n\"\n",
    "    summary_str += \"Non-trainable params: {0:,}\".format(total_params -\n",
    "                                                        trainable_params) + \"\\n\"\n",
    "    summary_str += \"----------------------------------------------------------------\" + \"\\n\"\n",
    "    summary_str += \"Input size (MB): %0.2f\" % total_input_size + \"\\n\"\n",
    "    summary_str += \"Forward/backward pass size (MB): %0.2f\" % total_output_size + \"\\n\"\n",
    "    summary_str += \"Params size (MB): %0.2f\" % total_params_size + \"\\n\"\n",
    "    summary_str += \"Estimated Total Size (MB): %0.2f\" % total_size + \"\\n\"\n",
    "    summary_str += \"----------------------------------------------------------------\" + \"\\n\"\n",
    "    # return summary\n",
    "    return summary_str, (total_params, trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiến thức bổ sung về pytorch\n",
    "\n",
    "#### Tìm hiểu về cấu trúc sparse trong pytorch\n",
    "https://towardsdatascience.com/sparse-matrices-in-pytorch-be8ecaccae6\n",
    "\n",
    "Cấu trúc sparse là cấu trúc mà thay vì lưu toàn bộ ma trận thì ta lưu chỉ số và giá trị của tất cả các phần tử khác 0\n",
    "\n",
    "=> Cấu trúc này thích hợp để lưu một mảng mà có nhiều phần tử bằng 0, giống như one_hot_encoding (Biểu diễn thành vector mà phần tử ở vị trí đó bằng 1, còn lại bằng 0)\n",
    "\n",
    "\n",
    "#### ctx là gì :\n",
    "\n",
    "ctx trong pytorch giống như biến self trong một class, dùng để chia sẻ thông tin lúc backward()  - đạo hàm ngược"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
